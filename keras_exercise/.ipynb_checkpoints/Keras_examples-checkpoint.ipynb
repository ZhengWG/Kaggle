{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras应用实例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考自 [keras_team](https://github.com/keras-team/keras/tree/master/examples)\n",
    "\n",
    "实例包括：图像（视频），文字（序列），生成模型，Keras特色功能实现，这里先简单探讨图像和Keras模型功能部分。\n",
    "\n",
    "软件环境：\n",
    "python3.5 tensorflow1.12.0 keras.2.2.4\n",
    "\n",
    "内容导航：\n",
    "\n",
    "* [1. 图像部分](#1)\n",
    "\n",
    "    * [1.1 Minist_MLP](#1.1)\n",
    "\n",
    "    * [1.2 CIFAR10 小图片分类示例(Sequential式)](#1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minist_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 17s 289us/step - loss: 0.2419 - acc: 0.9260 - val_loss: 0.1378 - val_acc: 0.9563\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.1039 - acc: 0.9698 - val_loss: 0.0789 - val_acc: 0.9759\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0743 - acc: 0.9776 - val_loss: 0.0839 - val_acc: 0.9754\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0597 - acc: 0.9820 - val_loss: 0.0776 - val_acc: 0.9797\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0494 - acc: 0.9851 - val_loss: 0.0889 - val_acc: 0.9793\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0437 - acc: 0.9867 - val_loss: 0.0748 - val_acc: 0.9818\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0399 - acc: 0.9882 - val_loss: 0.0847 - val_acc: 0.9804\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0333 - acc: 0.9901 - val_loss: 0.0757 - val_acc: 0.9832\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0312 - acc: 0.9907 - val_loss: 0.0847 - val_acc: 0.9825\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0283 - acc: 0.9919 - val_loss: 0.0814 - val_acc: 0.9836\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0253 - acc: 0.9927 - val_loss: 0.0938 - val_acc: 0.9815\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0255 - acc: 0.9926 - val_loss: 0.0906 - val_acc: 0.9821\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0211 - acc: 0.9935 - val_loss: 0.1134 - val_acc: 0.9804\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0224 - acc: 0.9937 - val_loss: 0.0971 - val_acc: 0.9839\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0237 - acc: 0.9938 - val_loss: 0.0961 - val_acc: 0.9819\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0192 - acc: 0.9944 - val_loss: 0.1032 - val_acc: 0.9840\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0202 - acc: 0.9944 - val_loss: 0.1047 - val_acc: 0.9832\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0180 - acc: 0.9955 - val_loss: 0.1054 - val_acc: 0.9816\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0192 - acc: 0.9951 - val_loss: 0.1253 - val_acc: 0.9819\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0189 - acc: 0.9952 - val_loss: 0.1063 - val_acc: 0.9821\n",
      "Test loss: 0.10632506377054074\n",
      "Test accuracy: 0.9821\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Trains a simple deep NN on the MNIST dataset.\n",
    "20 epochs\n",
    "acc: 0.9816\n",
    "Test loss: 0.11610001068654767\n",
    "Test accuracy: 0.9816\n",
    "about 6 seconds per epoch on a GeForce 940M GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# 将数据集分割为训练集和验证集\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# 类型标签需要转化为keras要求的binary class matrics格式\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"1.2\">1.2 CIFAR10 小图片分类示例（Sequential式）</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 122s 2ms/step - loss: 1.8311 - acc: 0.3345 - val_loss: 1.6657 - val_acc: 0.4035\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 111s 2ms/step - loss: 1.5049 - acc: 0.4567 - val_loss: 1.3474 - val_acc: 0.5146\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 1.3528 - acc: 0.5153 - val_loss: 1.2531 - val_acc: 0.5597\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 111s 2ms/step - loss: 1.2483 - acc: 0.5585 - val_loss: 1.1387 - val_acc: 0.5976\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 1.1618 - acc: 0.5917 - val_loss: 1.0871 - val_acc: 0.6129\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 115s 2ms/step - loss: 1.0942 - acc: 0.6180 - val_loss: 1.0086 - val_acc: 0.6451\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 1.0383 - acc: 0.6376 - val_loss: 1.0126 - val_acc: 0.6431\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.9970 - acc: 0.6500 - val_loss: 0.9596 - val_acc: 0.6581\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 0.9558 - acc: 0.6686 - val_loss: 0.8889 - val_acc: 0.6854\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 111s 2ms/step - loss: 0.9255 - acc: 0.6781 - val_loss: 0.8605 - val_acc: 0.6976\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 111s 2ms/step - loss: 0.8998 - acc: 0.6863 - val_loss: 0.8711 - val_acc: 0.6937\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 110s 2ms/step - loss: 0.8745 - acc: 0.6970 - val_loss: 0.8339 - val_acc: 0.7066\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 0.8500 - acc: 0.7048 - val_loss: 0.8314 - val_acc: 0.7133\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8319 - acc: 0.7119 - val_loss: 0.8137 - val_acc: 0.7161\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.8099 - acc: 0.7187 - val_loss: 0.7881 - val_acc: 0.7241\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 86s 2ms/step - loss: 0.7941 - acc: 0.7254 - val_loss: 0.8105 - val_acc: 0.7192\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.7766 - acc: 0.7324 - val_loss: 0.7911 - val_acc: 0.7241\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.7653 - acc: 0.7361 - val_loss: 0.7359 - val_acc: 0.7421\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.7556 - acc: 0.7377 - val_loss: 0.7487 - val_acc: 0.7437\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 75s 2ms/step - loss: 0.7440 - acc: 0.7440 - val_loss: 0.7302 - val_acc: 0.7474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8cd7b1b438>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Trains a simple deep NN on the CIFAR10 dataset.\n",
    "20 epochs\n",
    "acc(data auged): 0.6818(train),0.7230(val)\n",
    "Test loss: 0.8004208864212036\n",
    "Test accuracy: 0.723\n",
    "about 77 seconds per epoch on a GeForce 940M GPU.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "# data_augmentation = True\n",
    "# num_predictions = 20\n",
    "\n",
    "# 数据载入\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# 多分类标签生成\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# 网络结构配置\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# 训练参数设置\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成训练数据\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# 无数据增强进行训练\n",
    "print('Not using data augmentation.')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/20\n",
      "1562/1562 [==============================] - 68s 44ms/step - loss: 1.8172 - acc: 0.3348 - val_loss: 1.5825 - val_acc: 0.4202\n",
      "Epoch 2/20\n",
      "1562/1562 [==============================] - 68s 43ms/step - loss: 1.5852 - acc: 0.4221 - val_loss: 1.4322 - val_acc: 0.4794\n",
      "Epoch 3/20\n",
      "1562/1562 [==============================] - 72s 46ms/step - loss: 1.4609 - acc: 0.4720 - val_loss: 1.3075 - val_acc: 0.5254\n",
      "Epoch 4/20\n",
      "1562/1562 [==============================] - 73s 47ms/step - loss: 1.3757 - acc: 0.5065 - val_loss: 1.1862 - val_acc: 0.5771\n",
      "Epoch 5/20\n",
      "1562/1562 [==============================] - 74s 47ms/step - loss: 1.3029 - acc: 0.5371 - val_loss: 1.1373 - val_acc: 0.5927\n",
      "Epoch 6/20\n",
      "1562/1562 [==============================] - 78s 50ms/step - loss: 1.2501 - acc: 0.5535 - val_loss: 1.1786 - val_acc: 0.5838\n",
      "Epoch 7/20\n",
      "1562/1562 [==============================] - 78s 50ms/step - loss: 1.2071 - acc: 0.5704 - val_loss: 1.0379 - val_acc: 0.6281\n",
      "Epoch 8/20\n",
      "1562/1562 [==============================] - 78s 50ms/step - loss: 1.1705 - acc: 0.5858 - val_loss: 1.0924 - val_acc: 0.6180\n",
      "Epoch 9/20\n",
      "1562/1562 [==============================] - 78s 50ms/step - loss: 1.1352 - acc: 0.6012 - val_loss: 1.0783 - val_acc: 0.6285\n",
      "Epoch 10/20\n",
      "1562/1562 [==============================] - 78s 50ms/step - loss: 1.1033 - acc: 0.6117 - val_loss: 0.9947 - val_acc: 0.6515\n",
      "Epoch 11/20\n",
      "1562/1562 [==============================] - 78s 50ms/step - loss: 1.0768 - acc: 0.6206 - val_loss: 1.0336 - val_acc: 0.6323\n",
      "Epoch 12/20\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 1.0511 - acc: 0.6332 - val_loss: 0.9094 - val_acc: 0.6791\n",
      "Epoch 13/20\n",
      "1562/1562 [==============================] - 78s 50ms/step - loss: 1.0251 - acc: 0.6381 - val_loss: 0.9096 - val_acc: 0.6755\n",
      "Epoch 14/20\n",
      "1562/1562 [==============================] - 78s 50ms/step - loss: 1.0056 - acc: 0.6471 - val_loss: 0.8570 - val_acc: 0.6995\n",
      "Epoch 15/20\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 0.9874 - acc: 0.6542 - val_loss: 0.9028 - val_acc: 0.6851\n",
      "Epoch 16/20\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 0.9740 - acc: 0.6592 - val_loss: 0.8249 - val_acc: 0.7121\n",
      "Epoch 17/20\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 0.9581 - acc: 0.6642 - val_loss: 0.8329 - val_acc: 0.7088\n",
      "Epoch 18/20\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.9416 - acc: 0.6722 - val_loss: 0.8716 - val_acc: 0.6998\n",
      "Epoch 19/20\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 0.9323 - acc: 0.6758 - val_loss: 0.8601 - val_acc: 0.7030\n",
      "Epoch 20/20\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 0.9186 - acc: 0.6818 - val_loss: 0.8004 - val_acc: 0.7230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf80eefc88>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Using real-time data augmentation.')\n",
    "# 进行数据预处理和实时的数据增强:\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # 是否控制输入数据集的均值为0\n",
    "    samplewise_center=False,  # 是否控制样本均值为0\n",
    "    featurewise_std_normalization=False,  # 全部输入是否除以数据集的标准偏差(std)\n",
    "    samplewise_std_normalization=False,  # 每个输入是否除以数据集的标准偏差\n",
    "    zca_whitening=False,  # 是否应用ZCA白化\n",
    "    rotation_range=0,  # 随机旋转(度数,0-180°)\n",
    "    width_shift_range=0.1,  # 随机水平平移(整个宽度比例)\n",
    "    height_shift_range=0.1,  # 随机竖直平移(整个高度比例)\n",
    "    horizontal_flip=True,  # 随机水平翻转\n",
    "    vertical_flip=False)  # 随机竖直翻转\n",
    "\n",
    "# 生成训练增强数据\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# fit训练\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at models/keras_cifar10_trained_model.h5 \n",
      "10000/10000 [==============================] - 4s 378us/step\n",
      "Test loss: 0.8004208864212036\n",
      "Test accuracy: 0.723\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "save_dir = 'models/'\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# 保存模型和权重\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# 测试训练模型\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet训练CIFAR10 小图片分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model         | n   | 200-epoch accuracy | Original paper accuracy | sec/epoch GTX1080Ti |\n",
    "|---------------|-----|--------------------|-------------------------|---------------------|\n",
    "| ResNet20 v1   | 3   | 92.16%             | 91.25%                  | 35                  |\n",
    "| Resnet32 v1   | 5   | 92.46%             | 92.49%                  | 50                  |\n",
    "| Resnet44 v1   | 7   | 92.50%             | 92.83%                  | 70                  |\n",
    "| Resnet56 v1   | 9   | 92.71%             | 93.03%                  | 90                  |\n",
    "| Resnet110 v1  | 18  | 92.65%             | 93.39+-.16%             | 165                 |\n",
    "| Resnet164 v1  | 27  | -                  | 94.07%                  | -                   |\n",
    "| Resnet1001 v1 | N/A | -                  | 92.39%                  | -                   |\n",
    "\n",
    "\n",
    "| Model         | n   | 200-epoch accuracy | Original paper accuracy | sec/epoch GTX1080Ti |\n",
    "|---------------|-----|--------------------|-------------------------|---------------------|\n",
    "| ResNet20 v2   | 2   | -%                 | -%                      | --                  |\n",
    "| Resnet32 v2   | N/A | NA%                | NA%                     | NA                  |\n",
    "| Resnet44 v2   | N/A | NA%                | NA%                     | NA                  |\n",
    "| Resnet56 v2   | 6   | 93.01%             | NA%                     | 100                 |\n",
    "| Resnet110 v2  | 12  | 93.15%             | 93.63%                  | 180                 |\n",
    "| Resnet164 v2  | 18  | -                  | 94.54%                  | -                   |\n",
    "| Resnet1001 v2 | 111 | -                  | 95.08+-.14%             | -                   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# 训练参数\n",
    "batch_size = 16  # 原文中训练网络的batch_size为128, 官网为32\n",
    "epochs = 20\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "\n",
    "# 提取像素点均值以提高精度\n",
    "subtract_pixel_mean = True\n",
    "n = 3\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "# ResNet模型的版本\n",
    "# 原始论文版本：version = 1 (ResNet v1), 改进的ResNet: version = 2 (ResNet v2)\n",
    "version = 1\n",
    "\n",
    "# 不同的版本网络深度不一样，与模型参数n有关\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# 模型命名，深度，版本\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "# 加载CIFAR10数据\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# 输入图片的维度\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# 标准化数据\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# 进行数据的均值操作(mean)\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# 将类型向量转化为二值类型矩阵（keras支持的格式）\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    学习率规划:\n",
    "    学习率分别在80,120,160,180 epochs进行下降\n",
    "    在训练每个epoch后通过调用callbacks进行学习率的调整\n",
    "    \n",
    "    #参数\n",
    "        epoch(int):epochs数目\n",
    "    #返回值\n",
    "        lr(float):学习率\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"\n",
    "    定义基本的2D 卷积-BN-激活堆栈生成器(stack builder)\n",
    "    \n",
    "    #参数：\n",
    "        inputsr):从输入图片或者之前层中输入的张量(tensor)\n",
    "        num_filters(int):2维卷积，滤波器数目\n",
    "        kernel_size(int):2维卷积卷积核二维尺寸\n",
    "        activation(string):激活类型名称\n",
    "        batch_notmalization(bool):是否包含BN层\n",
    "        conv_first(bool):是否卷积层先，conv-bn-activation(True)或者bn-activation-conv(False)\n",
    "        \n",
    "    #返回值:\n",
    "        x(tensor):作为下一层的输入张量(tensor)\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"\n",
    "    ResNet V1 模型构建\n",
    "    \n",
    "    网络为最基本结构的堆栈组合(stacks):2x(3x3) Conv2D-BN-ReLu结构，3x3为卷积核\n",
    "    该结构中最后的relu层在short-cut连接之后.\n",
    "    整个网络分为三个stages，每个stage前面的特征图(feature map)需要降采样(downsampled),\n",
    "    通过一个步长(strides)为2的卷积层实现。\n",
    "    每个阶段(stage)的卷积核(filter)数目都会加倍。\n",
    "    相同阶段内保持相同的卷积核数目和卷积特征图大小。\n",
    "    各个阶段的特征图大小为:\n",
    "    stage 0:32x32, 16\n",
    "    stage 1:16x16, 32\n",
    "    stage 2:8x8,   64\n",
    "    模型大小如下：\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "    \n",
    "    # 输入参数\n",
    "        input_shape (tensor):输入图片tensor的尺寸(shape)\n",
    "        depth(int):核心卷积层数目\n",
    "        num_classed(int):图像分类类别(CIFAR10 有10类)\n",
    "        \n",
    "    # 返回值\n",
    "        model (Model):keras的模型实例\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # 开始实现模型的定义\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # 残差单元(residual units)堆栈(stack)的实例实现\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # 每个stack的首层但是不是第一stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # 每个stack的首层但是不是第一stack\n",
    "                # 因为进行了特征图的降采样，所以需要在shortcut连接(shortcut connection)过程中,'\n",
    "                # 进行线性投影(linear projection)以匹配降采样后的维度\n",
    "                # 通过strides变换的卷积网络实现\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # 在上层添加分类器\n",
    "    # v1版本没有在最后的shortcut connection-Relu后添加BN层\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x) # Flatten层用来将输入压平，常用于从卷积层到全连接层的过渡\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y) #he正态分布初始化\n",
    "\n",
    "    # 实例化模型\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    \"\"\"\n",
    "    ResNet V2 模型构建\n",
    "    网络最基本的堆栈组合为:(1X1)-(3x3)-(1x1)BN-RELU-Conv2D,称之为bottleneck层结构\n",
    "    每个stage(stack)第一层shortcut connection层需要接1x1 Conv2D卷积层，进行尺寸转换\n",
    "    接下来的第二层以及之后层则直连完成shortcut connection\n",
    "    每个stage的开始阶段，特征图都需要先进行降采样(downsampled),\n",
    "    通过strides=2的卷积层实现，filters数目需要翻倍。\n",
    "    每个stage内，每层都拥有相同数目的滤波器数目和特征图大小。\n",
    "    特征图大小如下：\n",
    "    conv1 : 32x32, 16\n",
    "    stage 0:32x32, 64\n",
    "    stage 1:16x16, 128\n",
    "    stage 2:8x8,   256\n",
    "    \n",
    "    # 输入参数\n",
    "        input_shape(tensor):输入图片tensor的尺寸(shape)\n",
    "        depth(int):核心卷积层的数目\n",
    "        num_class(int):类别数目(CIFAR10类别为10)\n",
    "        \n",
    "    # 返回值\n",
    "        model (Model):Keras模型实例\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # 开始模型定义\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2版本在分离输入tensor为两个路径(paths)之前需要先进行卷积(Conv2D with BN-ReLU)\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # 残差单元堆栈实例化\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # 第一个stage的第一层\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # 第一层，但非第一 stage\n",
    "                    strides = 2    # 需要降采样\n",
    "\n",
    "            # bottleneck残差单元\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # 卷积操作进行shortcut connection的线性映射以匹配变化了的维度\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # 在上层添加分类器网络\n",
    "    # v2版本在池化(Pooling)前需要添加BN-ReLU层\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # 实例化模型\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 32, 32, 16)   448         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 32, 32, 16)   64          conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 32, 32, 16)   0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 32, 32, 16)   2320        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 32, 32, 16)   64          conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 32, 32, 16)   0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 32, 32, 16)   2320        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 32, 32, 16)   64          conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 32, 32, 16)   0           activation_77[0][0]              \n",
      "                                                                 batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 32, 32, 16)   0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 32, 32, 16)   2320        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 32, 32, 16)   64          conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 32, 32, 16)   0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 32, 32, 16)   2320        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 32, 32, 16)   64          conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 32, 32, 16)   0           activation_79[0][0]              \n",
      "                                                                 batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 32, 32, 16)   0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 32, 32, 16)   2320        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 32, 32, 16)   64          conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 32, 32, 16)   0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 32, 32, 16)   2320        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 32, 32, 16)   64          conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 32, 32, 16)   0           activation_81[0][0]              \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 32, 32, 16)   0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 16, 16, 32)   4640        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 16, 16, 32)   128         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 16, 16, 32)   0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 16, 16, 32)   9248        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 16, 16, 32)   544         activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 16, 16, 32)   128         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 16, 16, 32)   0           conv2d_94[0][0]                  \n",
      "                                                                 batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 16, 16, 32)   0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 16, 16, 32)   9248        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 16, 16, 32)   128         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 16, 16, 32)   0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 16, 16, 32)   9248        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 16, 16, 32)   128         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 16, 16, 32)   0           activation_85[0][0]              \n",
      "                                                                 batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 16, 16, 32)   0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 16, 16, 32)   9248        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 16, 16, 32)   128         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 16, 16, 32)   0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 16, 16, 32)   9248        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 16, 16, 32)   128         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 16, 16, 32)   0           activation_87[0][0]              \n",
      "                                                                 batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 16, 16, 32)   0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 8, 8, 64)     18496       activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 64)     256         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 64)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 8, 8, 64)     36928       activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 8, 8, 64)     2112        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 64)     256         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 8, 8, 64)     0           conv2d_101[0][0]                 \n",
      "                                                                 batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 64)     0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 8, 8, 64)     36928       activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 64)     256         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 64)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 8, 8, 64)     36928       activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 64)     256         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 8, 8, 64)     0           activation_91[0][0]              \n",
      "                                                                 batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 64)     0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 8, 8, 64)     36928       activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 64)     256         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 64)     0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 8, 8, 64)     36928       activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 8, 8, 64)     256         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 8, 8, 64)     0           activation_93[0][0]              \n",
      "                                                                 batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 8, 8, 64)     0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 1, 1, 64)     0           activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 64)           0           average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           650         flatten_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 274,442\n",
      "Trainable params: 273,066\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n",
      "ResNet20v1\n",
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 312s 100ms/step - loss: 1.5947 - acc: 0.4818 - val_loss: 1.5713 - val_acc: 0.5164\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.51640, saving model to models/cifar10_ResNet20v1_model.001.h5\n",
      "Epoch 2/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 265s 85ms/step - loss: 1.2072 - acc: 0.6370 - val_loss: 1.3945 - val_acc: 0.6066\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.51640 to 0.60660, saving model to models/cifar10_ResNet20v1_model.002.h5\n",
      "Epoch 3/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 276s 88ms/step - loss: 1.0676 - acc: 0.6917 - val_loss: 0.9612 - val_acc: 0.7268\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.60660 to 0.72680, saving model to models/cifar10_ResNet20v1_model.003.h5\n",
      "Epoch 4/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 261s 84ms/step - loss: 0.9786 - acc: 0.7284 - val_loss: 1.1044 - val_acc: 0.6874\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.72680\n",
      "Epoch 5/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 261s 84ms/step - loss: 0.9215 - acc: 0.7491 - val_loss: 0.9581 - val_acc: 0.7372\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.72680 to 0.73720, saving model to models/cifar10_ResNet20v1_model.005.h5\n",
      "Epoch 6/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 261s 84ms/step - loss: 0.8801 - acc: 0.7683 - val_loss: 0.8495 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.73720 to 0.78350, saving model to models/cifar10_ResNet20v1_model.006.h5\n",
      "Epoch 7/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 260s 83ms/step - loss: 0.8514 - acc: 0.7766 - val_loss: 1.1488 - val_acc: 0.6938\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.78350\n",
      "Epoch 8/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 260s 83ms/step - loss: 0.8275 - acc: 0.7875 - val_loss: 0.8583 - val_acc: 0.7840\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.78350 to 0.78400, saving model to models/cifar10_ResNet20v1_model.008.h5\n",
      "Epoch 9/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 260s 83ms/step - loss: 0.8053 - acc: 0.7958 - val_loss: 0.9273 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.78400\n",
      "Epoch 10/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 260s 83ms/step - loss: 0.7858 - acc: 0.8045 - val_loss: 0.8533 - val_acc: 0.7881\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.78400 to 0.78810, saving model to models/cifar10_ResNet20v1_model.010.h5\n",
      "Epoch 11/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 261s 83ms/step - loss: 0.7727 - acc: 0.8092 - val_loss: 1.0937 - val_acc: 0.7302\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.78810\n",
      "Epoch 12/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 260s 83ms/step - loss: 0.7609 - acc: 0.8139 - val_loss: 0.7869 - val_acc: 0.8089\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.78810 to 0.80890, saving model to models/cifar10_ResNet20v1_model.012.h5\n",
      "Epoch 13/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 259s 83ms/step - loss: 0.7482 - acc: 0.8195 - val_loss: 0.8320 - val_acc: 0.7997\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.80890\n",
      "Epoch 14/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 260s 83ms/step - loss: 0.7348 - acc: 0.8249 - val_loss: 0.7548 - val_acc: 0.8166\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.80890 to 0.81660, saving model to models/cifar10_ResNet20v1_model.014.h5\n",
      "Epoch 15/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 260s 83ms/step - loss: 0.7285 - acc: 0.8258 - val_loss: 1.0691 - val_acc: 0.7290\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.81660\n",
      "Epoch 16/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 264s 84ms/step - loss: 0.7197 - acc: 0.8296 - val_loss: 0.8380 - val_acc: 0.7988\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.81660\n",
      "Epoch 17/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 263s 84ms/step - loss: 0.7089 - acc: 0.8344 - val_loss: 0.8024 - val_acc: 0.8096\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.81660\n",
      "Epoch 18/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 348s 111ms/step - loss: 0.7017 - acc: 0.8357 - val_loss: 0.7371 - val_acc: 0.8262\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.81660 to 0.82620, saving model to models/cifar10_ResNet20v1_model.018.h5\n",
      "Epoch 19/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 300s 96ms/step - loss: 0.6954 - acc: 0.8394 - val_loss: 0.7666 - val_acc: 0.8267\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.82620 to 0.82670, saving model to models/cifar10_ResNet20v1_model.019.h5\n",
      "Epoch 20/20\n",
      "Learning rate:  0.001\n",
      "3125/3125 [==============================] - 276s 88ms/step - loss: 0.6929 - acc: 0.8393 - val_loss: 0.8844 - val_acc: 0.7866\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.82670\n",
      "10000/10000 [==============================] - 13s 1ms/step\n",
      "Test loss: 0.8843909492492675\n",
      "Test accuracy: 0.7866\n"
     ]
    }
   ],
   "source": [
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)\n",
    "\n",
    "# 设置模型存储路径\n",
    "# save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "save_dir = 'models/'\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# 设置callbacks函数进行回调保存模型和调整学习率\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# 模型训练,有(无)数据增强\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # 进行图片预处理与实时的数据增强：\n",
    "    datagen = ImageDataGenerator(\n",
    "        # 控制输入数据集的均值为0\n",
    "        featurewise_center=False,\n",
    "        # 控制单个样本均值为0\n",
    "        samplewise_center=False,\n",
    "        # 全部输入是否除以数据集的标准偏差(std)\n",
    "        featurewise_std_normalization=False,\n",
    "        # 每个输入是否除以数据集的标准偏差\n",
    "        samplewise_std_normalization=False,\n",
    "        # 是否应用ZCA白化\n",
    "        zca_whitening=False,\n",
    "        # ZCA白化的最小表示值(epsilon)\n",
    "        zca_epsilon=1e-06,\n",
    "        # 随机旋转(度数,0-180°)\n",
    "        rotation_range=0,\n",
    "        # 随机水平平移(整个宽度比例)\n",
    "        width_shift_range=0.1,\n",
    "        # 随机竖直平移(整个高度比例)\n",
    "        height_shift_range=0.1,\n",
    "        # 设置随机仿射(shear)变换范围\n",
    "        shear_range=0.,\n",
    "        # 设置随机放大缩小范围(zoom)\n",
    "        zoom_range=0.,\n",
    "        # 设置随机通道偏移(channel shift)范围\n",
    "        channel_shift_range=0.,\n",
    "        # 输入边界外部填充点模式设置\n",
    "        fill_mode='nearest',\n",
    "        # 对于fill_mode=\"constant\"的value参数设置\n",
    "        cval=0.,\n",
    "        # 是否随机翻转(水平)\n",
    "        horizontal_flip=True,\n",
    "        # 是否随机翻转(竖直)\n",
    "        vertical_flip=False,\n",
    "        # 设置缩放因子(在应用其他所有变换之前都要设置)\n",
    "        rescale=None,\n",
    "        # 设置对每个输入应用的预处理函数\n",
    "        preprocessing_function=None,\n",
    "        # 图片数据格式，\"channels_first\"或者\"channels_last\"\n",
    "        data_format=None,\n",
    "        # 用于验证的图片数目组成分数(0-1之间)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # 生成训练增强数据\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # fit训练\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size, # 可能是版本的问题，需要提供该参数，数据集轮数\n",
    "                        epochs=epochs, verbose=1, workers=4,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# 评价训练得到的模型\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自建数据网络训练(Sequential式)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用自己下载设计的数据进行简单网络的训练，自己下载的数据包含5类:bus,dinosaur,elephant,flower,horse\n",
    "\n",
    "数据集一共有500张图片，每类各100张，其中验证集20张，训练集80张"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (400, 150, 150, 3)\n",
      "400 train samples\n",
      "100 test samples\n",
      "y_train shape: (400, 5)\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 67s 3s/step - loss: 1.6735 - acc: 0.4050 - val_loss: 1.0056 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.76000, saving model to models/zheng_modified_class_5.h5\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.7659 - acc: 0.7275 - val_loss: 0.5802 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.76000 to 0.86000, saving model to models/zheng_modified_class_5.h5\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.4671 - acc: 0.8150 - val_loss: 0.3572 - val_acc: 0.8700\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.86000 to 0.87000, saving model to models/zheng_modified_class_5.h5\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.3692 - acc: 0.8525 - val_loss: 0.2851 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.87000 to 0.91000, saving model to models/zheng_modified_class_5.h5\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.2937 - acc: 0.8800 - val_loss: 0.3219 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91000\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.2116 - acc: 0.9275 - val_loss: 0.2274 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91000 to 0.92000, saving model to models/zheng_modified_class_5.h5\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.2254 - acc: 0.9350 - val_loss: 0.2014 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92000\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.1936 - acc: 0.9225 - val_loss: 0.1638 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.92000 to 0.94000, saving model to models/zheng_modified_class_5.h5\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.1691 - acc: 0.9475 - val_loss: 0.2036 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.94000\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 64s 3s/step - loss: 0.1728 - acc: 0.9350 - val_loss: 0.2097 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.94000\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.1659 - acc: 0.9425 - val_loss: 0.1664 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.94000\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 64s 3s/step - loss: 0.1241 - acc: 0.9550 - val_loss: 0.2884 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.94000\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 64s 3s/step - loss: 0.1380 - acc: 0.9475 - val_loss: 0.2632 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.94000\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 64s 3s/step - loss: 0.0900 - acc: 0.9725 - val_loss: 0.1592 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.94000 to 0.95000, saving model to models/zheng_modified_class_5.h5\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 64s 3s/step - loss: 0.0779 - acc: 0.9725 - val_loss: 0.1438 - val_acc: 0.9600\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.95000 to 0.96000, saving model to models/zheng_modified_class_5.h5\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 64s 3s/step - loss: 0.0703 - acc: 0.9775 - val_loss: 0.1696 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.96000\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 64s 3s/step - loss: 0.0763 - acc: 0.9725 - val_loss: 0.1851 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.96000\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 64s 3s/step - loss: 0.0627 - acc: 0.9775 - val_loss: 0.1442 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.96000\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 64s 3s/step - loss: 0.0597 - acc: 0.9750 - val_loss: 0.1813 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.96000\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 64s 3s/step - loss: 0.0714 - acc: 0.9775 - val_loss: 0.2327 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.96000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-293bf40e170c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     callbacks=callbacks)\n\u001b[0;32m--> 189\u001b[0;31m \u001b[0mplot_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-293bf40e170c>\u001b[0m in \u001b[0;36mplot_training\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'history'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# GPU性能不够，禁用GPU，用CPU来跑\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "batch_size = 16\n",
    "num_classes = 5 # 五类\n",
    "epochs = 20\n",
    "data_augmentation = True\n",
    "# num_predictions = 20\n",
    "\n",
    "# 分割加载数据\n",
    "image_dir = 'pics/class_5/all'\n",
    "class_name = ('bus', 'dinasour', 'elephant', 'flower', 'horse')\n",
    "# 读取在all里面有几个文件夹，即为几个类别\n",
    "text = os.listdir(image_dir)\n",
    "def read_image(imageName):\n",
    "    #im = Image.open(imageName).convert('L')\n",
    "    img = image.load_img(imageName, target_size=(150, 150))\n",
    "    data = image.img_to_array(img)\n",
    "    return data\n",
    "\n",
    "# 画图，将训练时的acc和loss都绘制到图上\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def plot_training(history):\n",
    "    plt.figure(12)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    train_acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    epochs = range(len(train_acc))\n",
    "    plt.plot(epochs, train_acc, 'b',label='train_acc')\n",
    "    plt.plot(epochs, val_acc, 'r',label='test_acc')\n",
    "    plt.title('Train and Test accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(train_loss))\n",
    "    plt.plot(epochs, train_loss, 'b',label='train_loss')\n",
    "    plt.plot(epochs, val_loss, 'r',label='test_loss')\n",
    "    plt.title('Train and Test loss')\n",
    "    plt.legend()\n",
    " \n",
    "    plt.show()\n",
    "\n",
    "# 把文件夹里面的图片和对应文件夹名字对应得到类别信息(label)\n",
    "images = []\n",
    "labels = []\n",
    "for textPath in text:\n",
    "    for fn in os.listdir(os.path.join(image_dir, textPath)):\n",
    "        if fn.endswith('.jpg'):\n",
    "            fd = os.path.join(image_dir, textPath, fn)\n",
    "            images.append(read_image(fd))\n",
    "            labels.append(textPath)\n",
    "# 将images和labels变成numpy数组类型\n",
    "X = np.array(images)\n",
    "y = np.array(list(map(int, labels)))\n",
    "# 进行训练集和测试集的拆分\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=30)\n",
    "# 多分类标签生成\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('x_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# 网络结构配置\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(150,150,3))) #输入size可调\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# 训练参数设置\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\"\"\"\n",
    "# 生成训练数据\n",
    "# 进行数据预处理和实时的数据增强:\n",
    "print('Using real-time data augmentation.')\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # 像素点转数字0-1，张量数字除以255\n",
    "    rotation_range=40,  # 随机旋转(度数,0-180°)\n",
    "    horizontal_flip=True,  # 随机水平翻转\n",
    "    shear_range=0.2, # 剪切强度\n",
    "    zoom_range=0.2, # 随机缩放的幅度\n",
    "    vertical_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # 验证集数据无需增强  \n",
    "\n",
    "# 生成训练增强数据\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'pics/class_5/train', \n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')                               # matt，多分类\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'pics/class_5/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')                             # matt，多分类\n",
    "\n",
    "# fit训练\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_generator.__iter__().n/batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=validation_generator.__iter__().n/batch_size)\n",
    "                \n",
    "model.save_weights('models/zheng_modified_class_5.h5')  \n",
    "\"\"\"\n",
    "\n",
    "# 生成训练数据\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# 生成训练增强数据\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,  # 随机旋转(度数,0-180°)\n",
    "    horizontal_flip=True,  # 随机水平翻转\n",
    "    shear_range=0.2, # 剪切强度\n",
    "    zoom_range=0.2, # 随机缩放的幅度\n",
    "    vertical_flip=True)\n",
    "train_datagen.fit(X_train)\n",
    "\n",
    "# 设置callbacks函数进行回调保存模型和调整学习率\n",
    "filepath = 'models/zheng_modified_class_5.h5'\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer]\n",
    "\n",
    "# fit训练\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "H = model.fit_generator(train_datagen.flow(X_train, y_train,batch_size=batch_size),\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    steps_per_epoch=X_train.shape[0] // batch_size, # 可能是版本的问题，需要提供该参数，数据集轮数\n",
    "                    epochs=epochs, verbose=1, workers=4,\n",
    "                    callbacks=callbacks)\n",
    "plot_training(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (400,)\n",
      "400 train samples\n",
      "100 test samples\n",
      "y_train shape: (400,)\n",
      "preds: [[1.4979191e-05 7.9999238e-01 1.9997072e-01 5.3960689e-06 1.6465221e-05]]\n",
      "Prdicted type: dinasour\n",
      "Score: 0.7999924\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# GPU性能不够，禁用GPU，用CPU来跑\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# 加载模型(模型需要定义好结构)\n",
    "# 网络结构配置\n",
    "num_classes = 5\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(150,150,3))) #输入size可调\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.load_weights('models/zheng_modified_class_5.h5')\n",
    "\"\"\"\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "# 评价模型(理论上测试数据应该是独立，这里仅作示例)\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\"\"\"\n",
    "# 模型预测输出\n",
    "img_path = 'pics/class_5/dinasour.jpeg'\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "img_x = image.img_to_array(img)\n",
    "# axis=0中添加数据,扩展数组\n",
    "img_x = np.expand_dims(img_x/255, axis=0)\n",
    "\n",
    "preds = model.predict(img_x)\n",
    "# 将结果解码为元组列表 (class, description, probability)\n",
    "# (一个列表代表批次中的一个样本）\n",
    "print ('preds:', preds)\n",
    "print ('Prdicted type:',class_name[np.argmax(preds, axis=1)[0]])\n",
    "print ('Score:',np.max(preds, axis=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR(未运行)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-*- coding: utf-8 -*-\n",
    "'''\n",
    "# Optical character recognition\n",
    "This example uses a convolutional stack followed by a recurrent stack\n",
    "and a CTC logloss function to perform optical character recognition\n",
    "of generated text images. I have no evidence of whether it actually\n",
    "learns general shapes of text, or just is able to recognize all\n",
    "the different fonts thrown at it...the purpose is more to demonstrate CTC\n",
    "inside of Keras.  Note that the font list may need to be updated\n",
    "for the particular OS in use.\n",
    "This starts off with 4 letter words.  For the first 12 epochs, the\n",
    "difficulty is gradually increased using the TextImageGenerator class\n",
    "which is both a generator class for test/train data and a Keras\n",
    "callback class. After 20 epochs, longer sequences are thrown at it\n",
    "by recompiling the model to handle a wider image and rebuilding\n",
    "the word list to include two words separated by a space.\n",
    "The table below shows normalized edit distance values. Theano uses\n",
    "a slightly different CTC implementation, hence the different results.\n",
    "Epoch |   TF   |   TH\n",
    "-----:|-------:|-------:\n",
    "    10|  0.027 | 0.064\n",
    "    15|  0.038 | 0.035\n",
    "    20|  0.043 | 0.045\n",
    "    25|  0.014 | 0.019\n",
    "This requires ```cairo``` and ```editdistance``` packages:\n",
    "```python\n",
    "pip install cairocffi\n",
    "pip install editdistance\n",
    "```\n",
    "Created by Mike Henry\n",
    "https://github.com/mbhenry/\n",
    "'''\n",
    "import os\n",
    "import itertools\n",
    "import codecs\n",
    "import re\n",
    "import datetime\n",
    "import cairocffi as cairo\n",
    "import editdistance\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pylab\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks\n",
    "\n",
    "\n",
    "OUTPUT_DIR = 'image_ocr'\n",
    "\n",
    "# character classes and matching regex filter\n",
    "regex = r'^[a-z ]+$'\n",
    "alphabet = u'abcdefghijklmnopqrstuvwxyz '\n",
    "\n",
    "np.random.seed(55)\n",
    "\n",
    "\n",
    "# this creates larger \"blotches\" of noise which look\n",
    "# more realistic than just adding gaussian noise\n",
    "# assumes greyscale with pixels ranging from 0 to 1\n",
    "\n",
    "def speckle(img):\n",
    "    severity = np.random.uniform(0, 0.6)\n",
    "    blur = ndimage.gaussian_filter(np.random.randn(*img.shape) * severity, 1)\n",
    "    img_speck = (img + blur)\n",
    "    img_speck[img_speck > 1] = 1\n",
    "    img_speck[img_speck <= 0] = 0\n",
    "    return img_speck\n",
    "\n",
    "\n",
    "# paints the string in a random location the bounding box\n",
    "# also uses a random font, a slight random rotation,\n",
    "# and a random amount of speckle noise\n",
    "\n",
    "def paint_text(text, w, h, rotate=False, ud=False, multi_fonts=False):\n",
    "    surface = cairo.ImageSurface(cairo.FORMAT_RGB24, w, h)\n",
    "    with cairo.Context(surface) as context:\n",
    "        context.set_source_rgb(1, 1, 1)  # White\n",
    "        context.paint()\n",
    "        # this font list works in CentOS 7\n",
    "        if multi_fonts:\n",
    "            fonts = [\n",
    "                'Century Schoolbook', 'Courier', 'STIX',\n",
    "                'URW Chancery L', 'FreeMono']\n",
    "            context.select_font_face(\n",
    "                np.random.choice(fonts),\n",
    "                cairo.FONT_SLANT_NORMAL,\n",
    "                np.random.choice([cairo.FONT_WEIGHT_BOLD, cairo.FONT_WEIGHT_NORMAL]))\n",
    "        else:\n",
    "            context.select_font_face('Courier',\n",
    "                                     cairo.FONT_SLANT_NORMAL,\n",
    "                                     cairo.FONT_WEIGHT_BOLD)\n",
    "        context.set_font_size(25)\n",
    "        box = context.text_extents(text)\n",
    "        border_w_h = (4, 4)\n",
    "        if box[2] > (w - 2 * border_w_h[1]) or box[3] > (h - 2 * border_w_h[0]):\n",
    "            raise IOError(('Could not fit string into image.'\n",
    "                           'Max char count is too large for given image width.'))\n",
    "\n",
    "        # teach the RNN translational invariance by\n",
    "        # fitting text box randomly on canvas, with some room to rotate\n",
    "        max_shift_x = w - box[2] - border_w_h[0]\n",
    "        max_shift_y = h - box[3] - border_w_h[1]\n",
    "        top_left_x = np.random.randint(0, int(max_shift_x))\n",
    "        if ud:\n",
    "            top_left_y = np.random.randint(0, int(max_shift_y))\n",
    "        else:\n",
    "            top_left_y = h // 2\n",
    "        context.move_to(top_left_x - int(box[0]), top_left_y - int(box[1]))\n",
    "        context.set_source_rgb(0, 0, 0)\n",
    "        context.show_text(text)\n",
    "\n",
    "    buf = surface.get_data()\n",
    "    a = np.frombuffer(buf, np.uint8)\n",
    "    a.shape = (h, w, 4)\n",
    "    a = a[:, :, 0]  # grab single channel\n",
    "    a = a.astype(np.float32) / 255\n",
    "    a = np.expand_dims(a, 0)\n",
    "    if rotate:\n",
    "        a = image.random_rotation(a, 3 * (w - top_left_x) / w + 1)\n",
    "    a = speckle(a)\n",
    "\n",
    "    return a\n",
    "\n",
    "\n",
    "def shuffle_mats_or_lists(matrix_list, stop_ind=None):\n",
    "    ret = []\n",
    "    assert all([len(i) == len(matrix_list[0]) for i in matrix_list])\n",
    "    len_val = len(matrix_list[0])\n",
    "    if stop_ind is None:\n",
    "        stop_ind = len_val\n",
    "    assert stop_ind <= len_val\n",
    "\n",
    "    a = list(range(stop_ind))\n",
    "    np.random.shuffle(a)\n",
    "    a += list(range(stop_ind, len_val))\n",
    "    for mat in matrix_list:\n",
    "        if isinstance(mat, np.ndarray):\n",
    "            ret.append(mat[a])\n",
    "        elif isinstance(mat, list):\n",
    "            ret.append([mat[i] for i in a])\n",
    "        else:\n",
    "            raise TypeError('`shuffle_mats_or_lists` only supports '\n",
    "                            'numpy.array and list objects.')\n",
    "    return ret\n",
    "\n",
    "\n",
    "# Translation of characters to unique integer values\n",
    "def text_to_labels(text):\n",
    "    ret = []\n",
    "    for char in text:\n",
    "        ret.append(alphabet.find(char))\n",
    "    return ret\n",
    "\n",
    "\n",
    "# Reverse translation of numerical classes back to characters\n",
    "def labels_to_text(labels):\n",
    "    ret = []\n",
    "    for c in labels:\n",
    "        if c == len(alphabet):  # CTC Blank\n",
    "            ret.append(\"\")\n",
    "        else:\n",
    "            ret.append(alphabet[c])\n",
    "    return \"\".join(ret)\n",
    "\n",
    "\n",
    "# only a-z and space..probably not to difficult\n",
    "# to expand to uppercase and symbols\n",
    "\n",
    "def is_valid_str(in_str):\n",
    "    search = re.compile(regex, re.UNICODE).search\n",
    "    return bool(search(in_str))\n",
    "\n",
    "\n",
    "# Uses generator functions to supply train/test with\n",
    "# data. Image renderings and text are created on the fly\n",
    "# each time with random perturbations\n",
    "\n",
    "class TextImageGenerator(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, monogram_file, bigram_file, minibatch_size,\n",
    "                 img_w, img_h, downsample_factor, val_split,\n",
    "                 absolute_max_string_len=16):\n",
    "\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.img_w = img_w\n",
    "        self.img_h = img_h\n",
    "        self.monogram_file = monogram_file\n",
    "        self.bigram_file = bigram_file\n",
    "        self.downsample_factor = downsample_factor\n",
    "        self.val_split = val_split\n",
    "        self.blank_label = self.get_output_size() - 1\n",
    "        self.absolute_max_string_len = absolute_max_string_len\n",
    "\n",
    "    def get_output_size(self):\n",
    "        return len(alphabet) + 1\n",
    "\n",
    "    # num_words can be independent of the epoch size due to the use of generators\n",
    "    # as max_string_len grows, num_words can grow\n",
    "    def build_word_list(self, num_words, max_string_len=None, mono_fraction=0.5):\n",
    "        assert max_string_len <= self.absolute_max_string_len\n",
    "        assert num_words % self.minibatch_size == 0\n",
    "        assert (self.val_split * num_words) % self.minibatch_size == 0\n",
    "        self.num_words = num_words\n",
    "        self.string_list = [''] * self.num_words\n",
    "        tmp_string_list = []\n",
    "        self.max_string_len = max_string_len\n",
    "        self.Y_data = np.ones([self.num_words, self.absolute_max_string_len]) * -1\n",
    "        self.X_text = []\n",
    "        self.Y_len = [0] * self.num_words\n",
    "\n",
    "        def _is_length_of_word_valid(word):\n",
    "            return (max_string_len == -1 or\n",
    "                    max_string_len is None or\n",
    "                    len(word) <= max_string_len)\n",
    "\n",
    "        # monogram file is sorted by frequency in english speech\n",
    "        with codecs.open(self.monogram_file, mode='r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if len(tmp_string_list) == int(self.num_words * mono_fraction):\n",
    "                    break\n",
    "                word = line.rstrip()\n",
    "                if _is_length_of_word_valid(word):\n",
    "                    tmp_string_list.append(word)\n",
    "\n",
    "        # bigram file contains common word pairings in english speech\n",
    "        with codecs.open(self.bigram_file, mode='r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if len(tmp_string_list) == self.num_words:\n",
    "                    break\n",
    "                columns = line.lower().split()\n",
    "                word = columns[0] + ' ' + columns[1]\n",
    "                if is_valid_str(word) and _is_length_of_word_valid(word):\n",
    "                    tmp_string_list.append(word)\n",
    "        if len(tmp_string_list) != self.num_words:\n",
    "            raise IOError('Could not pull enough words'\n",
    "                          'from supplied monogram and bigram files.')\n",
    "        # interlace to mix up the easy and hard words\n",
    "        self.string_list[::2] = tmp_string_list[:self.num_words // 2]\n",
    "        self.string_list[1::2] = tmp_string_list[self.num_words // 2:]\n",
    "\n",
    "        for i, word in enumerate(self.string_list):\n",
    "            self.Y_len[i] = len(word)\n",
    "            self.Y_data[i, 0:len(word)] = text_to_labels(word)\n",
    "            self.X_text.append(word)\n",
    "        self.Y_len = np.expand_dims(np.array(self.Y_len), 1)\n",
    "\n",
    "        self.cur_val_index = self.val_split\n",
    "        self.cur_train_index = 0\n",
    "\n",
    "    # each time an image is requested from train/val/test, a new random\n",
    "    # painting of the text is performed\n",
    "    def get_batch(self, index, size, train):\n",
    "        # width and height are backwards from typical Keras convention\n",
    "        # because width is the time dimension when it gets fed into the RNN\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            X_data = np.ones([size, 1, self.img_w, self.img_h])\n",
    "        else:\n",
    "            X_data = np.ones([size, self.img_w, self.img_h, 1])\n",
    "\n",
    "        labels = np.ones([size, self.absolute_max_string_len])\n",
    "        input_length = np.zeros([size, 1])\n",
    "        label_length = np.zeros([size, 1])\n",
    "        source_str = []\n",
    "        for i in range(size):\n",
    "            # Mix in some blank inputs.  This seems to be important for\n",
    "            # achieving translational invariance\n",
    "            if train and i > size - 4:\n",
    "                if K.image_data_format() == 'channels_first':\n",
    "                    X_data[i, 0, 0:self.img_w, :] = self.paint_func('')[0, :, :].T\n",
    "                else:\n",
    "                    X_data[i, 0:self.img_w, :, 0] = self.paint_func('',)[0, :, :].T\n",
    "                labels[i, 0] = self.blank_label\n",
    "                input_length[i] = self.img_w // self.downsample_factor - 2\n",
    "                label_length[i] = 1\n",
    "                source_str.append('')\n",
    "            else:\n",
    "                if K.image_data_format() == 'channels_first':\n",
    "                    X_data[i, 0, 0:self.img_w, :] = (\n",
    "                        self.paint_func(self.X_text[index + i])[0, :, :].T)\n",
    "                else:\n",
    "                    X_data[i, 0:self.img_w, :, 0] = (\n",
    "                        self.paint_func(self.X_text[index + i])[0, :, :].T)\n",
    "                labels[i, :] = self.Y_data[index + i]\n",
    "                input_length[i] = self.img_w // self.downsample_factor - 2\n",
    "                label_length[i] = self.Y_len[index + i]\n",
    "                source_str.append(self.X_text[index + i])\n",
    "        inputs = {'the_input': X_data,\n",
    "                  'the_labels': labels,\n",
    "                  'input_length': input_length,\n",
    "                  'label_length': label_length,\n",
    "                  'source_str': source_str  # used for visualization only\n",
    "                  }\n",
    "        outputs = {'ctc': np.zeros([size])}  # dummy data for dummy loss function\n",
    "        return (inputs, outputs)\n",
    "\n",
    "    def next_train(self):\n",
    "        while 1:\n",
    "            ret = self.get_batch(self.cur_train_index,\n",
    "                                 self.minibatch_size, train=True)\n",
    "            self.cur_train_index += self.minibatch_size\n",
    "            if self.cur_train_index >= self.val_split:\n",
    "                self.cur_train_index = self.cur_train_index % 32\n",
    "                (self.X_text, self.Y_data, self.Y_len) = shuffle_mats_or_lists(\n",
    "                    [self.X_text, self.Y_data, self.Y_len], self.val_split)\n",
    "            yield ret\n",
    "\n",
    "    def next_val(self):\n",
    "        while 1:\n",
    "            ret = self.get_batch(self.cur_val_index,\n",
    "                                 self.minibatch_size, train=False)\n",
    "            self.cur_val_index += self.minibatch_size\n",
    "            if self.cur_val_index >= self.num_words:\n",
    "                self.cur_val_index = self.val_split + self.cur_val_index % 32\n",
    "            yield ret\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.build_word_list(16000, 4, 1)\n",
    "        self.paint_func = lambda text: paint_text(\n",
    "            text, self.img_w, self.img_h,\n",
    "            rotate=False, ud=False, multi_fonts=False)\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        # rebind the paint function to implement curriculum learning\n",
    "        if 3 <= epoch < 6:\n",
    "            self.paint_func = lambda text: paint_text(\n",
    "                text, self.img_w, self.img_h,\n",
    "                rotate=False, ud=True, multi_fonts=False)\n",
    "        elif 6 <= epoch < 9:\n",
    "            self.paint_func = lambda text: paint_text(\n",
    "                text, self.img_w, self.img_h,\n",
    "                rotate=False, ud=True, multi_fonts=True)\n",
    "        elif epoch >= 9:\n",
    "            self.paint_func = lambda text: paint_text(\n",
    "                text, self.img_w, self.img_h,\n",
    "                rotate=True, ud=True, multi_fonts=True)\n",
    "        if epoch >= 21 and self.max_string_len < 12:\n",
    "            self.build_word_list(32000, 12, 0.5)\n",
    "\n",
    "\n",
    "# the actual loss calc occurs here despite it not being\n",
    "# an internal Keras loss function\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "# For a real OCR application, this should be beam search with a dictionary\n",
    "# and language model.  For this example, best path is sufficient.\n",
    "\n",
    "def decode_batch(test_func, word_batch):\n",
    "    out = test_func([word_batch])[0]\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "        outstr = labels_to_text(out_best)\n",
    "        ret.append(outstr)\n",
    "    return ret\n",
    "\n",
    "\n",
    "class VizCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, run_name, test_func, text_img_gen, num_display_words=6):\n",
    "        self.test_func = test_func\n",
    "        self.output_dir = os.path.join(\n",
    "            OUTPUT_DIR, run_name)\n",
    "        self.text_img_gen = text_img_gen\n",
    "        self.num_display_words = num_display_words\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def show_edit_distance(self, num):\n",
    "        num_left = num\n",
    "        mean_norm_ed = 0.0\n",
    "        mean_ed = 0.0\n",
    "        while num_left > 0:\n",
    "            word_batch = next(self.text_img_gen)[0]\n",
    "            num_proc = min(word_batch['the_input'].shape[0], num_left)\n",
    "            decoded_res = decode_batch(self.test_func,\n",
    "                                       word_batch['the_input'][0:num_proc])\n",
    "            for j in range(num_proc):\n",
    "                edit_dist = editdistance.eval(decoded_res[j],\n",
    "                                              word_batch['source_str'][j])\n",
    "                mean_ed += float(edit_dist)\n",
    "                mean_norm_ed += float(edit_dist) / len(word_batch['source_str'][j])\n",
    "            num_left -= num_proc\n",
    "        mean_norm_ed = mean_norm_ed / num\n",
    "        mean_ed = mean_ed / num\n",
    "        print('\\nOut of %d samples:  Mean edit distance:'\n",
    "              '%.3f Mean normalized edit distance: %0.3f'\n",
    "              % (num, mean_ed, mean_norm_ed))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.model.save_weights(\n",
    "            os.path.join(self.output_dir, 'weights%02d.h5' % (epoch)))\n",
    "        self.show_edit_distance(256)\n",
    "        word_batch = next(self.text_img_gen)[0]\n",
    "        res = decode_batch(self.test_func,\n",
    "                           word_batch['the_input'][0:self.num_display_words])\n",
    "        if word_batch['the_input'][0].shape[0] < 256:\n",
    "            cols = 2\n",
    "        else:\n",
    "            cols = 1\n",
    "        for i in range(self.num_display_words):\n",
    "            pylab.subplot(self.num_display_words // cols, cols, i + 1)\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                the_input = word_batch['the_input'][i, 0, :, :]\n",
    "            else:\n",
    "                the_input = word_batch['the_input'][i, :, :, 0]\n",
    "            pylab.imshow(the_input.T, cmap='Greys_r')\n",
    "            pylab.xlabel(\n",
    "                'Truth = \\'%s\\'\\nDecoded = \\'%s\\'' %\n",
    "                (word_batch['source_str'][i], res[i]))\n",
    "        fig = pylab.gcf()\n",
    "        fig.set_size_inches(10, 13)\n",
    "        pylab.savefig(os.path.join(self.output_dir, 'e%02d.png' % (epoch)))\n",
    "        pylab.close()\n",
    "\n",
    "\n",
    "def train(run_name, start_epoch, stop_epoch, img_w):\n",
    "    # Input Parameters\n",
    "    img_h = 64\n",
    "    words_per_epoch = 16000\n",
    "    val_split = 0.2\n",
    "    val_words = int(words_per_epoch * (val_split))\n",
    "\n",
    "    # Network parameters\n",
    "    conv_filters = 16\n",
    "    kernel_size = (3, 3)\n",
    "    pool_size = 2\n",
    "    time_dense_size = 32\n",
    "    rnn_size = 512\n",
    "    minibatch_size = 32\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, img_w, img_h)\n",
    "    else:\n",
    "        input_shape = (img_w, img_h, 1)\n",
    "\n",
    "    fdir = os.path.dirname(\n",
    "        get_file('wordlists.tgz',\n",
    "                 origin='http://www.mythic-ai.com/datasets/wordlists.tgz',\n",
    "                 untar=True))\n",
    "\n",
    "    img_gen = TextImageGenerator(\n",
    "        monogram_file=os.path.join(fdir, 'wordlist_mono_clean.txt'),\n",
    "        bigram_file=os.path.join(fdir, 'wordlist_bi_clean.txt'),\n",
    "        minibatch_size=minibatch_size,\n",
    "        img_w=img_w,\n",
    "        img_h=img_h,\n",
    "        downsample_factor=(pool_size ** 2),\n",
    "        val_split=words_per_epoch - val_words)\n",
    "    act = 'relu'\n",
    "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv1')(input_data)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv2')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    "\n",
    "    conv_to_rnn_dims = (img_w // (pool_size ** 2),\n",
    "                        (img_h // (pool_size ** 2)) * conv_filters)\n",
    "    inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "\n",
    "    # cuts down input size going into RNN:\n",
    "    inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "    # Two layers of bidirectional GRUs\n",
    "    # GRU seems to work as well, if not better than LSTM:\n",
    "    gru_1 = GRU(rnn_size, return_sequences=True,\n",
    "                kernel_initializer='he_normal', name='gru1')(inner)\n",
    "    gru_1b = GRU(rnn_size, return_sequences=True,\n",
    "                 go_backwards=True, kernel_initializer='he_normal',\n",
    "                 name='gru1_b')(inner)\n",
    "    gru1_merged = add([gru_1, gru_1b])\n",
    "    gru_2 = GRU(rnn_size, return_sequences=True,\n",
    "                kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True,\n",
    "                 kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    inner = Dense(img_gen.get_output_size(), kernel_initializer='he_normal',\n",
    "                  name='dense2')(concatenate([gru_2, gru_2b]))\n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "    Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "    labels = Input(name='the_labels',\n",
    "                   shape=[img_gen.absolute_max_string_len], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    # Keras doesn't currently support loss funcs with extra parameters\n",
    "    # so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(\n",
    "        ctc_lambda_func, output_shape=(1,),\n",
    "        name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    # clipnorm seems to speeds up convergence\n",
    "    sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\n",
    "    model = Model(inputs=[input_data, labels, input_length, label_length],\n",
    "                  outputs=loss_out)\n",
    "\n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "    if start_epoch > 0:\n",
    "        weight_file = os.path.join(\n",
    "            OUTPUT_DIR,\n",
    "            os.path.join(run_name, 'weights%02d.h5' % (start_epoch - 1)))\n",
    "        model.load_weights(weight_file)\n",
    "    # captures output of softmax so we can decode the output during visualization\n",
    "    test_func = K.function([input_data], [y_pred])\n",
    "\n",
    "    viz_cb = VizCallback(run_name, test_func, img_gen.next_val())\n",
    "\n",
    "    model.fit_generator(\n",
    "        generator=img_gen.next_train(),\n",
    "        steps_per_epoch=(words_per_epoch - val_words) // minibatch_size,\n",
    "        epochs=stop_epoch,\n",
    "        validation_data=img_gen.next_val(),\n",
    "        validation_steps=val_words // minibatch_size,\n",
    "        callbacks=[viz_cb, img_gen],\n",
    "        initial_epoch=start_epoch)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_name = datetime.datetime.now().strftime('%Y:%m:%d:%H:%M:%S')\n",
    "    train(run_name, 0, 20, 128)\n",
    "    # increase to wider images and start at epoch 20.\n",
    "    # The learned weights are reloaded\n",
    "    train(run_name, 20, 25, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型迁移与微调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新类上微调Inception V3\n",
    "利用上文中的自建数据进行网络的训练，包括五类:bus,dinosaur,elephant,flower,horse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (400, 150, 150, 3)\n",
      "400 train samples\n",
      "100 test samples\n",
      "y_train shape: (400, 5)\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 28s 1s/step - loss: 4.2790 - val_loss: 1.0434\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 25s 1s/step - loss: 0.6132 - val_loss: 6.3256\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 25s 1s/step - loss: 0.8956 - val_loss: 6.3695\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 25s 1s/step - loss: 0.6580 - val_loss: 0.6842\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 25s 1s/step - loss: 0.5508 - val_loss: 0.1060\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 25s 1s/step - loss: 0.7072 - val_loss: 0.3450\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 25s 1s/step - loss: 0.8701 - val_loss: 0.0905\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.2620 - val_loss: 1.1013\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 25s 1s/step - loss: 0.5287 - val_loss: 0.1001\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 25s 1s/step - loss: 0.3893 - val_loss: 0.0961\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.5456 - val_loss: 0.2403\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.3710 - val_loss: 0.1007\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.4414 - val_loss: 0.1127\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.1476 - val_loss: 0.1536\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.3848 - val_loss: 0.1868\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.1789 - val_loss: 3.4320\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.6229 - val_loss: 2.4227\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.3490 - val_loss: 0.3363\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 27s 1s/step - loss: 0.3856 - val_loss: 0.2104\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.1687 - val_loss: 0.2565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f324d708c50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# GPU性能不够，禁用GPU，用CPU来跑\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "batch_size = 16\n",
    "num_classes = 5 # 五类\n",
    "epochs = 20\n",
    "data_augmentation = True\n",
    "# num_predictions = 20\n",
    "\n",
    "# 分割加载数据\n",
    "image_dir = 'pics/class_5/all'\n",
    "class_name = ('bus', 'dinasour', 'elephant', 'flower', 'horse')\n",
    "# 读取在all里面有几个文件夹，即为几个类别\n",
    "text = os.listdir(image_dir)\n",
    "def read_image(imageName):\n",
    "    #im = Image.open(imageName).convert('L')\n",
    "    img = image.load_img(imageName, target_size=(150, 150))\n",
    "    data = image.img_to_array(img)\n",
    "    return data\n",
    "# 把文件夹里面的图片和对应文件夹名字对应得到类别信息(label)\n",
    "images = []\n",
    "labels = []\n",
    "for textPath in text:\n",
    "    for fn in os.listdir(os.path.join(image_dir, textPath)):\n",
    "        if fn.endswith('.jpg'):\n",
    "            fd = os.path.join(image_dir, textPath, fn)\n",
    "            images.append(read_image(fd))\n",
    "            labels.append(textPath)\n",
    "# 将images和labels变成numpy数组类型\n",
    "X = np.array(images)\n",
    "y = np.array(list(map(int, labels)))\n",
    "# 进行训练集和测试集的拆分\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=30)\n",
    "# 多分类标签生成\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('x_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# 生成训练数据\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# 生成训练增强数据\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,  # 随机旋转(度数,0-180°)\n",
    "    horizontal_flip=True,  # 随机水平翻转\n",
    "    shear_range=0.2, # 剪切强度\n",
    "    zoom_range=0.2, # 随机缩放的幅度\n",
    "    vertical_flip=True)\n",
    "train_datagen.fit(X_train)\n",
    "\n",
    "# 构建不带分类器的预训练模型:include_top=False\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# 添加全局平均池化层\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# 添加一个全连接层\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# 添加一个分类器，假设我们有5个类\n",
    "predictions = Dense(5, activation='softmax')(x)\n",
    "\n",
    "# 构建我们需要训练的完整模型\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 首先，我们只训练顶部的几层（随机初始化的层）\n",
    "# 锁住所有 InceptionV3 的卷积层\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# 编译模型（一定要在锁层以后操作）\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# 在新的数据集上训练几代\n",
    "# 参数:self,generator,steps_per_epoch,epochs,verbose,validation_data,\n",
    "# validation_steps,class_weight,sample_weight,workers,max_q_size,pickle_safe,initial_epoch\n",
    "# 重要的参数有:generator，为生成器函数，生成输入，target(标签)等数据输入;\n",
    "# steps_per_epoch:输入数据的batch数目，自动得到batches数目?\n",
    "# epochs:数据迭代数目\n",
    "# 可利用yield函数进行生成数据:如：\n",
    "# def generate_arrays_from_file(path):\n",
    "#    while 1:\n",
    "#    f = open(path)\n",
    "#    for line in f:\n",
    "#        x1, x2, y = process_line(line)\n",
    "#        yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
    "#    f.close()\n",
    "# model.fit_generator(generate_arrays_from_file('/my_file.txt'), steps_per_epoch=10000, epochs=10)\n",
    "\n",
    "model.fit_generator(train_datagen.flow(X_train, y_train,batch_size=batch_size),\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    steps_per_epoch=X_train.shape[0] // batch_size, # 可能是版本的问题，需要提供该参数，数据集轮数\n",
    "                    epochs=epochs, \n",
    "                    verbose=1, \n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.2769 - val_loss: 0.4863\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.48630, saving model to models/zheng_finetuned_step1_class_5.h5\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.1598 - val_loss: 0.3522\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.48630 to 0.35219, saving model to models/zheng_finetuned_step1_class_5.h5\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.1227 - val_loss: 0.3250\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.35219 to 0.32503, saving model to models/zheng_finetuned_step1_class_5.h5\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.0680 - val_loss: 0.3080\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.32503 to 0.30801, saving model to models/zheng_finetuned_step1_class_5.h5\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.0617 - val_loss: 0.3062\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.30801 to 0.30620, saving model to models/zheng_finetuned_step1_class_5.h5\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2089 - val_loss: 0.2825\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.30620 to 0.28251, saving model to models/zheng_finetuned_step1_class_5.h5\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.0591 - val_loss: 0.2758\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.28251 to 0.27579, saving model to models/zheng_finetuned_step1_class_5.h5\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.0474 - val_loss: 0.2599\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.27579 to 0.25987, saving model to models/zheng_finetuned_step1_class_5.h5\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.0346 - val_loss: 0.2503\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.25987 to 0.25033, saving model to models/zheng_finetuned_step1_class_5.h5\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.0512 - val_loss: 0.2570\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.25033\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.0645 - val_loss: 0.2453\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.25033 to 0.24531, saving model to models/zheng_finetuned_step1_class_5.h5\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.0602 - val_loss: 0.2460\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.24531\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.1001 - val_loss: 0.2356\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.24531 to 0.23563, saving model to models/zheng_finetuned_step1_class_5.h5\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.1213 - val_loss: 0.2317\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.23563 to 0.23165, saving model to models/zheng_finetuned_step1_class_5.h5\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.1267 - val_loss: 0.2298\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.23165 to 0.22977, saving model to models/zheng_finetuned_step1_class_5.h5\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.0280 - val_loss: 0.2290\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.22977 to 0.22905, saving model to models/zheng_finetuned_step1_class_5.h5\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.0899 - val_loss: 0.2533\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.22905\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.0346 - val_loss: 0.2458\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.22905\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.0607 - val_loss: 0.2434\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.22905\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.0378 - val_loss: 0.2389\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.22905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f324c780dd8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在顶层应该训练好了，让我们开始微调 Inception V3 的卷积层。\n",
    "# 我们会锁住底下的几层，然后训练其余的顶层。\n",
    "\n",
    "# 让我们看看每一层的名字和层号，查看应该锁多少层：\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "   # print(i, layer.name)\n",
    "\n",
    "# 我们选择训练最上面的两个 Inception block\n",
    "# 也就是说锁住前面249层，然后放开之后的层。\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# 我们需要重新编译模型，才能使上面的修改生效\n",
    "# 让我们设置一个很低的学习率，使用 SGD 来微调\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
    "\n",
    "# 设置callbacks函数进行回调保存模型和调整学习率\n",
    "filepath = 'models/zheng_finetuned_step1_class_5.h5'\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer]\n",
    "\n",
    "# 我们继续训练模型，这次我们训练最后两个 Inception block\n",
    "# 和两个全连接层\n",
    "model.fit_generator(train_datagen.flow(X_train, y_train,batch_size=batch_size),\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    steps_per_epoch=X_train.shape[0] // batch_size, # 可能是版本的问题，需要提供该参数，数据集轮数\n",
    "                    epochs=epochs, verbose=1, workers=4,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [[4.2442291e-08 7.0512516e-15 1.0000000e+00 2.4925725e-14 1.1243640e-16]]\n",
      "Prdicted type: elephant\n",
      "Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 模型预测输出\n",
    "img_path = 'pics/class_5/elephant.jpeg'\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "img_x = image.img_to_array(img)\n",
    "# axis=0中添加数据,扩展数组\n",
    "img_x = np.expand_dims(img_x/255, axis=0)\n",
    "\n",
    "preds = model.predict(img_x)\n",
    "# 将结果解码为元组列表 (class, description, probability)\n",
    "# (一个列表代表批次中的一个样本）\n",
    "print ('preds:', preds)\n",
    "print ('Prdicted type:',class_name[np.argmax(preds, axis=1)[0]])\n",
    "print ('Score:',np.max(preds, axis=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 激活图显示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_size: (1, 1000)\n",
      "cam_size: (1, 224, 224, 1000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "import keras.applications.resnet50 as resnet\n",
    "from keras.layers import UpSampling2D, Conv2D\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# GPU性能不够，禁用GPU，用CPU来跑\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# 设置图片文件位置\n",
    "INPUT_IMG_FILE = \"pics/class_5/elephant.jpeg\"\n",
    "\n",
    "################################################################\n",
    "# 也可以改为其他模型(有average pooling层)\n",
    "# 如 InceptionResnetV2 / NASNerLarge\n",
    "NETWORK_INPUT_SIZE = 224\n",
    "MODEL_CLASS = resnet.ResNet50\n",
    "PREPROCESS_FN = resnet.preprocess_input\n",
    "LAST_CONV_LAYER = \"activation_49\"\n",
    "PRED_LAYER = \"fc1000\"\n",
    "################################################################\n",
    "# imagenet的类别数目\n",
    "N_CLASSES = 1000\n",
    "\n",
    "\n",
    "def load_img(fname, input_size, preprocess_fn):\n",
    "    # 加载图片，得到size\n",
    "    # 扩充维度，得到模型输入张量\n",
    "    original_img = cv2.imread(fname)[:, :, ::-1]\n",
    "    original_size = (original_img.shape[1], original_img.shape[0])\n",
    "    img = cv2.resize(original_img, (input_size, input_size))\n",
    "    imgs = np.expand_dims(preprocess_fn(img), axis=0)\n",
    "    return imgs, original_img, original_size\n",
    "\n",
    "\n",
    "def get_cam_model(model_class,\n",
    "                  input_size=224,\n",
    "                  last_conv_layer=\"activation_49\",\n",
    "                  pred_layer=\"fc1000\"):\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph() #清空之前model占用的内存，以免产生层命名的混乱\n",
    "    \n",
    "    # 这里得到fc1000全连接层的参数，作为后添加的卷积层的参数\n",
    "    model = model_class(input_shape=(input_size, input_size, 3))\n",
    "    # model.summary()\n",
    "    final_params = model.get_layer(pred_layer).get_weights()\n",
    "    final_params = (final_params[0].reshape(\n",
    "        1, 1, -1, N_CLASSES), final_params[1])\n",
    "\n",
    "    # 卷积层的引入，先上采样到input_size(224=7*32)\n",
    "    # 再加入卷积层，两层连接到activation_49\n",
    "    last_conv_output = model.get_layer(last_conv_layer).output\n",
    "    x = UpSampling2D(size=(32, 32), interpolation=\"bilinear\")(\n",
    "        last_conv_output)\n",
    "    x = Conv2D(filters=N_CLASSES, kernel_size=(\n",
    "        1, 1), name=\"predictions_2\")(x)\n",
    "    \n",
    "    # 新的模型除了原先的输出外还有卷积激活图的输出\n",
    "    cam_model = Model(inputs=model.input,\n",
    "                      outputs=[model.output, x])\n",
    "    cam_model.get_layer(\"predictions_2\").set_weights(final_params)\n",
    "    # cam_model.summary()\n",
    "    return cam_model\n",
    "\n",
    "\n",
    "def postprocess(preds, cams, top_k=1):\n",
    "    idxes = np.argsort(preds[0])[-top_k:] #从小到大得到索引值排序，取其中最大为idxes\n",
    "    class_activation_map = np.zeros_like(cams[0, :, :, 0])\n",
    "    for i in idxes:\n",
    "        # 得到idxes(因为只有一项，所以只迭代一次)所在的激活值\n",
    "        class_activation_map += cams[0, :, :, i]\n",
    "    return class_activation_map\n",
    "\n",
    "\n",
    "# 1. 加载图片\n",
    "imgs, original_img, original_size = load_img(INPUT_IMG_FILE,\n",
    "                                             input_size=NETWORK_INPUT_SIZE,\n",
    "                                             preprocess_fn=resnet.preprocess_input)\n",
    "\n",
    "# 2. 得到修改后的cam模型并进行预测\n",
    "model = get_cam_model(resnet.ResNet50,\n",
    "                      NETWORK_INPUT_SIZE,\n",
    "                      LAST_CONV_LAYER,\n",
    "                      PRED_LAYER)\n",
    "preds, cams = model.predict(imgs)\n",
    "\n",
    "# 4. 通过预测值得到对应的最大响应激活图\n",
    "class_activation_map = postprocess(preds, cams)\n",
    "\n",
    "# 5. 将原图与cam激活图合并成原图的size\n",
    "%matplotlib inline\n",
    "plt.imshow(original_img, alpha=0.5)\n",
    "plt.imshow(cv2.resize(class_activation_map,\n",
    "                      original_size), cmap='jet', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 卷积层可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以VGG16为例进行卷积层的可视化，详细实现原理可参考[机器之心-卷积特征可视化](https://www.jiqizhixin.com/articles/2019-01-31-13)\n",
    "\n",
    "简而言之，卷积层可视化实际是对每层的卷积核的最大响应的图像进行生成。输入为随机噪声的灰度图，通过定义指定层的损失函数（将特征图激活后的均值作为损失函数），通过梯度上升的方式进行最大化激活值。最终反向生成能够得到相应卷积核最大激活输出的图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Compute filters 0 to 512\n",
      "Costs of filter   0:   688 ( 4.87s )\n",
      "Costs of filter   1:  1440 ( 5.90s )\n",
      "Costs of filter   3:   761 ( 4.95s )\n",
      "Costs of filter   4:  1282 ( 5.58s )\n",
      "Costs of filter   5:   454 ( 5.47s )\n",
      "Costs of filter   7:  1144 ( 6.69s )\n",
      "Costs of filter   9:   506 ( 5.25s )\n",
      "Costs of filter  14:   738 ( 5.84s )\n",
      "Costs of filter  15:   703 ( 5.28s )\n",
      "Costs of filter  16:   729 ( 5.04s )\n",
      "Costs of filter  17:  1070 ( 4.97s )\n",
      "Costs of filter  20:   616 ( 5.01s )\n",
      "Costs of filter  21:   870 ( 5.09s )\n",
      "Costs of filter  22:   869 ( 5.03s )\n",
      "Costs of filter  24:   493 ( 5.04s )\n",
      "Costs of filter  25:   765 ( 5.02s )\n",
      "Costs of filter  27:  1162 ( 5.60s )\n",
      "Costs of filter  29:   349 ( 5.23s )\n",
      "Costs of filter  30:   742 ( 5.72s )\n",
      "Costs of filter  36:   622 ( 5.38s )\n",
      "Costs of filter  39:   910 ( 5.18s )\n",
      "Costs of filter  40:   572 ( 5.27s )\n",
      "Costs of filter  42:   587 ( 5.29s )\n",
      "Costs of filter  44:  1016 ( 5.32s )\n",
      "Costs of filter  46:   830 ( 5.80s )\n",
      "Costs of filter  49:   698 ( 6.77s )\n",
      "Costs of filter  52:  1301 ( 6.34s )\n",
      "Costs of filter  53:   800 ( 5.64s )\n",
      "Costs of filter  54:  1371 ( 5.88s )\n",
      "Costs of filter  58:   507 ( 5.65s )\n",
      "Costs of filter  61:   723 ( 6.62s )\n",
      "Costs of filter  64:   974 ( 8.11s )\n",
      "Costs of filter  65:   707 ( 6.10s )\n",
      "Costs of filter  66:   521 ( 5.80s )\n",
      "Costs of filter  68:   931 ( 5.46s )\n",
      "Costs of filter  70:   774 ( 5.43s )\n",
      "Costs of filter  72:   913 ( 5.42s )\n",
      "Costs of filter  74:  1274 ( 5.43s )\n",
      "Costs of filter  75:   535 ( 5.46s )\n",
      "Costs of filter  79:   547 ( 5.52s )\n",
      "Costs of filter  82:   514 ( 5.79s )\n",
      "Costs of filter  84:   463 ( 5.57s )\n",
      "Costs of filter  85:   720 ( 5.54s )\n",
      "Costs of filter  87:   738 ( 6.31s )\n",
      "Costs of filter  88:   627 ( 6.45s )\n",
      "Costs of filter  89:   840 ( 6.18s )\n",
      "Costs of filter  90:  1148 ( 5.63s )\n",
      "Costs of filter  91:  1227 ( 5.75s )\n",
      "Costs of filter  94:   816 ( 5.67s )\n",
      "Costs of filter 103:   673 ( 5.75s )\n",
      "Costs of filter 109:   955 ( 5.83s )\n",
      "Costs of filter 110:   523 ( 5.86s )\n",
      "Costs of filter 111:   784 ( 5.84s )\n",
      "Costs of filter 112:   598 ( 5.86s )\n",
      "Costs of filter 114:   954 ( 5.89s )\n",
      "Costs of filter 116:   552 ( 6.00s )\n",
      "Costs of filter 117:  1761 ( 5.89s )\n",
      "Costs of filter 122:   744 ( 5.98s )\n",
      "Costs of filter 126:   927 ( 6.01s )\n",
      "Costs of filter 127:   887 ( 6.04s )\n",
      "Costs of filter 128:   793 ( 6.50s )\n",
      "Costs of filter 131:   447 ( 6.98s )\n",
      "Costs of filter 133:   447 ( 7.13s )\n",
      "Costs of filter 134:   700 ( 6.83s )\n",
      "Costs of filter 136:   764 ( 6.80s )\n",
      "Costs of filter 139:   595 ( 6.19s )\n",
      "Costs of filter 140:   461 ( 6.22s )\n",
      "Costs of filter 143:   810 ( 6.25s )\n",
      "Costs of filter 145:   727 ( 6.24s )\n",
      "Costs of filter 146:   849 ( 6.26s )\n",
      "Costs of filter 147:   774 ( 6.29s )\n",
      "Costs of filter 149:   338 ( 6.39s )\n",
      "Costs of filter 156:   911 ( 6.38s )\n",
      "Costs of filter 157:   976 ( 6.36s )\n",
      "Costs of filter 158:   991 ( 6.37s )\n",
      "Costs of filter 162:   792 ( 6.39s )\n",
      "Costs of filter 165:   752 ( 6.42s )\n",
      "Costs of filter 166:   838 ( 6.50s )\n",
      "Costs of filter 168:   557 ( 6.49s )\n",
      "Costs of filter 170:  1001 ( 6.51s )\n",
      "Costs of filter 171:   653 ( 6.54s )\n",
      "Costs of filter 172:  1060 ( 6.54s )\n",
      "Costs of filter 174:   692 ( 6.56s )\n",
      "Costs of filter 176:  1488 ( 6.65s )\n",
      "Costs of filter 177:   473 ( 6.66s )\n",
      "Costs of filter 179:   834 ( 6.83s )\n",
      "Costs of filter 181:   946 ( 6.60s )\n",
      "Costs of filter 182:   982 ( 6.66s )\n",
      "Costs of filter 187:   947 ( 6.68s )\n",
      "Costs of filter 194:   734 ( 6.83s )\n",
      "Costs of filter 195:   612 ( 6.84s )\n",
      "Costs of filter 196:   766 ( 6.87s )\n",
      "Costs of filter 201:   426 ( 6.93s )\n",
      "Costs of filter 203:   640 ( 6.94s )\n",
      "Costs of filter 205:  1639 ( 6.97s )\n",
      "Costs of filter 206:   356 ( 7.01s )\n",
      "Costs of filter 208:  1142 ( 6.93s )\n",
      "Costs of filter 213:   721 ( 7.06s )\n",
      "Costs of filter 218:   647 ( 7.04s )\n",
      "Costs of filter 219:   660 ( 7.17s )\n",
      "Costs of filter 220:  1653 ( 7.15s )\n",
      "Costs of filter 223:   420 ( 7.14s )\n",
      "Costs of filter 228:   725 ( 7.29s )\n",
      "Costs of filter 236:   528 ( 7.38s )\n",
      "Costs of filter 240:   813 ( 7.34s )\n",
      "Costs of filter 242:   942 ( 7.94s )\n",
      "Costs of filter 243:   914 ( 8.18s )\n",
      "Costs of filter 245:   828 ( 7.40s )\n",
      "Costs of filter 246:   362 ( 7.54s )\n",
      "Costs of filter 247:  1444 ( 7.50s )\n",
      "Costs of filter 251:   973 ( 7.50s )\n",
      "Costs of filter 253:   927 ( 7.56s )\n",
      "Costs of filter 255:   809 ( 7.54s )\n",
      "Costs of filter 257:  1059 ( 7.64s )\n",
      "Costs of filter 258:   680 ( 7.68s )\n",
      "Costs of filter 259:   519 ( 7.59s )\n",
      "Costs of filter 260:   462 ( 7.61s )\n",
      "Costs of filter 266:  1327 ( 7.67s )\n",
      "Costs of filter 268:   603 ( 7.95s )\n",
      "Costs of filter 269:   588 ( 7.84s )\n",
      "Costs of filter 270:  1116 ( 7.84s )\n",
      "Costs of filter 271:   705 ( 7.77s )\n",
      "Costs of filter 272:   598 ( 7.80s )\n",
      "Costs of filter 281:   766 ( 7.90s )\n",
      "Costs of filter 283:   546 ( 7.92s )\n",
      "Costs of filter 285:   727 ( 7.96s )\n",
      "Costs of filter 287:   533 ( 8.12s )\n",
      "Costs of filter 288:  1529 ( 8.11s )\n",
      "Costs of filter 289:   910 ( 8.14s )\n",
      "Costs of filter 292:   461 ( 8.08s )\n",
      "Costs of filter 293:   720 ( 8.20s )\n",
      "Costs of filter 295:   375 ( 8.40s )\n",
      "Costs of filter 297:   717 ( 8.27s )\n",
      "Costs of filter 300:   862 ( 8.18s )\n",
      "Costs of filter 303:   517 ( 8.17s )\n",
      "Costs of filter 306:  1385 ( 8.40s )\n",
      "Costs of filter 308:  1145 ( 8.40s )\n",
      "Costs of filter 310:   670 ( 8.34s )\n",
      "Costs of filter 311:   634 ( 8.34s )\n",
      "Costs of filter 316:   534 ( 8.40s )\n",
      "Costs of filter 319:   916 ( 8.42s )\n",
      "Costs of filter 320:   920 ( 8.48s )\n",
      "Costs of filter 322:   521 ( 8.60s )\n",
      "Costs of filter 323:   553 ( 8.57s )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costs of filter 327:   558 ( 8.55s )\n",
      "Costs of filter 328:  1131 ( 8.70s )\n",
      "Costs of filter 329:   607 ( 8.70s )\n",
      "Costs of filter 331:   689 ( 8.73s )\n",
      "Costs of filter 334:  1178 ( 8.64s )\n",
      "Costs of filter 335:   652 ( 8.67s )\n",
      "Costs of filter 339:   694 ( 9.14s )\n",
      "Costs of filter 341:   650 ( 8.90s )\n",
      "Costs of filter 346:   527 ( 8.83s )\n",
      "Costs of filter 347:   719 ( 9.00s )\n",
      "Costs of filter 348:   547 ( 8.91s )\n",
      "Costs of filter 350:   560 ( 8.92s )\n",
      "Costs of filter 352:   584 ( 9.07s )\n",
      "Costs of filter 353:   541 ( 9.07s )\n",
      "Costs of filter 354:   576 ( 9.12s )\n",
      "Costs of filter 355:  1128 ( 9.13s )\n",
      "Costs of filter 356:  1252 ( 9.18s )\n",
      "Costs of filter 357:   423 ( 9.29s )\n",
      "Costs of filter 359:   764 ( 9.16s )\n",
      "Costs of filter 360:   445 ( 9.10s )\n",
      "Costs of filter 365:   525 ( 9.13s )\n",
      "Costs of filter 368:   931 ( 9.18s )\n",
      "Costs of filter 369:  1029 ( 9.20s )\n",
      "Costs of filter 371:  1283 ( 9.39s )\n",
      "Costs of filter 375:   960 ( 9.44s )\n",
      "Costs of filter 378:   567 ( 9.36s )\n",
      "Costs of filter 383:   832 ( 9.42s )\n",
      "Costs of filter 387:   922 ( 9.63s )\n",
      "Costs of filter 390:   699 ( 9.76s )\n",
      "Costs of filter 391:  1119 ( 9.57s )\n",
      "Costs of filter 394:  1023 ( 9.63s )\n",
      "Costs of filter 395:   689 ( 9.81s )\n",
      "Costs of filter 397:   555 ( 9.69s )\n",
      "Costs of filter 399:   570 ( 9.68s )\n",
      "Costs of filter 405:   822 ( 9.91s )\n",
      "Costs of filter 406:   585 ( 10.06s )\n",
      "Costs of filter 407:   914 ( 10.02s )\n",
      "Costs of filter 410:  1100 ( 10.09s )\n",
      "Costs of filter 411:   443 ( 10.06s )\n",
      "Costs of filter 418:  1082 ( 10.06s )\n",
      "Costs of filter 421:   524 ( 10.33s )\n",
      "Costs of filter 422:   892 ( 10.12s )\n",
      "Costs of filter 424:   353 ( 10.17s )\n",
      "Costs of filter 427:   977 ( 10.31s )\n",
      "Costs of filter 428:  1256 ( 10.49s )\n",
      "Costs of filter 431:   970 ( 10.43s )\n",
      "Costs of filter 432:  1419 ( 10.59s )\n",
      "Costs of filter 434:   600 ( 10.65s )\n",
      "Costs of filter 435:   647 ( 10.37s )\n",
      "Costs of filter 436:  1008 ( 10.40s )\n",
      "Costs of filter 437:   516 ( 10.39s )\n",
      "Costs of filter 438:   591 ( 10.63s )\n",
      "Costs of filter 442:   746 ( 10.46s )\n",
      "Costs of filter 446:   722 ( 10.58s )\n",
      "Costs of filter 447:  1298 ( 10.90s )\n",
      "Costs of filter 449:   389 ( 10.79s )\n",
      "Costs of filter 450:   653 ( 10.84s )\n",
      "Costs of filter 452:   527 ( 10.69s )\n",
      "Costs of filter 453:   617 ( 10.90s )\n",
      "Costs of filter 458:   593 ( 11.02s )\n",
      "Costs of filter 459:   912 ( 10.83s )\n",
      "Costs of filter 461:   302 ( 10.85s )\n",
      "Costs of filter 464:   450 ( 10.97s )\n",
      "Costs of filter 465:   652 ( 11.16s )\n",
      "Costs of filter 467:   687 ( 10.99s )\n",
      "Costs of filter 468:   467 ( 11.07s )\n",
      "Costs of filter 469:   996 ( 11.08s )\n",
      "Costs of filter 471:   840 ( 11.26s )\n",
      "Costs of filter 473:   772 ( 11.33s )\n",
      "Costs of filter 474:   698 ( 11.35s )\n",
      "Costs of filter 475:   588 ( 11.12s )\n",
      "Costs of filter 476:   589 ( 11.68s )\n",
      "Costs of filter 481:   697 ( 13.18s )\n",
      "Costs of filter 482:   541 ( 15.79s )\n",
      "Costs of filter 483:   527 ( 13.27s )\n",
      "Costs of filter 485:   713 ( 12.31s )\n",
      "Costs of filter 486:  1268 ( 12.75s )\n",
      "Costs of filter 487:   748 ( 11.81s )\n",
      "Costs of filter 489:   376 ( 11.90s )\n",
      "Costs of filter 490:   662 ( 11.93s )\n",
      "Costs of filter 491:   593 ( 12.19s )\n",
      "Costs of filter 493:   606 ( 14.47s )\n",
      "Costs of filter 494:   717 ( 15.14s )\n",
      "Costs of filter 496:   594 ( 14.02s )\n",
      "Costs of filter 497:   708 ( 12.83s )\n",
      "Costs of filter 500:   745 ( 12.17s )\n",
      "Costs of filter 502:  1269 ( 12.06s )\n",
      "Costs of filter 503:   615 ( 12.31s )\n",
      "Costs of filter 505:   655 ( 12.59s )\n",
      "Costs of filter 511:   568 ( 14.09s )\n",
      "234 filter processed.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image as pil_image\n",
    "from keras.preprocessing.image import save_img\n",
    "from keras import layers\n",
    "from keras.applications import vgg16\n",
    "from keras import backend as K\n",
    "\n",
    "# GPU性能不够，禁用GPU，用CPU来跑\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    功能函数：标准化张量(tensor)\n",
    "\n",
    "    # 输入参数\n",
    "        x:输入张量\n",
    "    # 输出\n",
    "        输入张量的标准化输出\n",
    "    \"\"\"\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "    \"\"\"\n",
    "    功能函数:将浮点数数组转化为有效的uint8类型图片\n",
    "    \n",
    "    # 输入参数\n",
    "        x:代表生成图片的Numpy向量数组\n",
    "    # 输出\n",
    "        处理过的numpy数组，能够通过imshow等方式显示的图片格式\n",
    "    \"\"\"\n",
    "    # normalize tensor: center on 0., ensure std is 0.25\n",
    "    # 标准化张量:数值中心保持为0，\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.25\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "\n",
    "def process_image(x, former):\n",
    "    \"\"\"\n",
    "    功能函数:将有效的uint8类型图片格式转化为浮点数数组\n",
    "    为'deprocess_image'的反向操作\n",
    "    \n",
    "    # 输入参数\n",
    "        x:numpy数值，能够通过imshow等进行显示\n",
    "        fromer: 之前的numpy-array数据.\n",
    "                需要确定之前的均值(mean)和variance(方差).\n",
    "                \n",
    "    #返回值\n",
    "        处理过的代表图片的numpy数组\n",
    "    \"\"\"\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((2, 0, 1))\n",
    "    return (x / 255 - 0.5) * 4 * former.std() + former.mean()\n",
    "\n",
    "\n",
    "# 默认size为412*412，太慢了，改成52*52\n",
    "def visualize_layer(model,\n",
    "                    layer_name,\n",
    "                    step=1.,\n",
    "                    epochs=15,\n",
    "                    upscaling_steps=9,\n",
    "                    upscaling_factor=1.2,\n",
    "                    output_dim=(52,52),\n",
    "                    filter_range=(0, None)):\n",
    "    \"\"\"\n",
    "    可视化得到模型指定层最大相关的滤波器(通过激活层的均值大小判断)\n",
    "    \n",
    "    #输入参数\n",
    "        model:包含层名称的模型\n",
    "        layer_name:需要进行可视化的层名称，需要为模型的一部分\n",
    "        step:梯度上升的步长大小(step size)\n",
    "        epochs:梯度上升的迭代轮数\n",
    "        upscaling_steps:upscaling的步长数目,upscaling用于生成图的扩大\n",
    "                        初始图像大小为(80,80)，最终图像为(412,412)\n",
    "        upscaling_factor:用于缓慢更新图像大小的参数(factor)，最终大小为输出大小\n",
    "                        　如官方80->412为412=80*(1.2)**9\n",
    "        output_dim:[img_width, img_height]输出图像尺寸\n",
    "        filter_range:Tupel类型[lower,upper]\n",
    "                     确定了需要计算的卷积核(滤波器)序号范围\n",
    "                     如果upper参数为'None'，\n",
    "                     则将最后一个卷积核序号作为上限\n",
    "    \"\"\"\n",
    "\n",
    "    def _generate_filter_image(input_img,\n",
    "                               layer_output,\n",
    "                               filter_index):\n",
    "        \"\"\"\n",
    "        生成指定卷积核的图像\n",
    "        \n",
    "        # 输入参数\n",
    "            input_img:输入图像张量\n",
    "            layer_output:输出图像张量\n",
    "            filter_index:需要进行处理的滤波器序号\n",
    "                        　需保证序号有效\n",
    "            \n",
    "        # 返回值\n",
    "            返回None，如无图片\n",
    "            如有图片，则返回tuple类型的图片数组(iamge array)以及最终的loss值\n",
    "        \"\"\"\n",
    "        s_time = time.time()\n",
    "\n",
    "        # 这里建立了一个损失函数来最大化对应层的nth卷积核的激活值\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "        else:\n",
    "            loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "        # 根据loss计算对输入图片的梯度值\n",
    "        grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "        # 正则化技巧(normalization trick):需要标准化梯度值\n",
    "        grads = normalize(grads)\n",
    "\n",
    "        # 该函数返回得到输入图片的损失值和梯度值\n",
    "        iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "        # 初始图片为随机噪声的灰度图\n",
    "        intermediate_dim = tuple(\n",
    "            int(x / (upscaling_factor ** upscaling_steps)) for x in output_dim)\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            input_img_data = np.random.random(\n",
    "                (1, 3, intermediate_dim[0], intermediate_dim[1]))\n",
    "        else:\n",
    "            input_img_data = np.random.random(\n",
    "                (1, intermediate_dim[0], intermediate_dim[1], 3))\n",
    "        input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "        # 这里需要逐步扩增到原先的大小(original size),\n",
    "        # 主要是为了防止可视化结构(visualized structure)的主导高频(domminating highj-frequency)现象\n",
    "        # 这种情况可能会在我们直接计算412维度图像的时候发生。\n",
    "        # 从低维开始更容易在每个维度有一个更好的开始点(starting point),\n",
    "        # 能有效防止局部最小值的出现(poor local minima)\n",
    "        for up in reversed(range(upscaling_steps)):\n",
    "            # 逐步进行梯度上升,如20 steps\n",
    "            for _ in range(epochs):\n",
    "                loss_value, grads_value = iterate([input_img_data])\n",
    "                input_img_data += grads_value * step　#step默认为1\n",
    "\n",
    "                # 一些卷积核可能输出为0，需要跳过\n",
    "                if loss_value <= K.epsilon():\n",
    "                    return None\n",
    "\n",
    "            # 计算扩增的维度\n",
    "            intermediate_dim = tuple(\n",
    "                int(x / (upscaling_factor ** up)) for x in output_dim)\n",
    "            # 得到扩增图像数据\n",
    "            img = deprocess_image(input_img_data[0])\n",
    "            img = np.array(pil_image.fromarray(img).resize(intermediate_dim,\n",
    "                                                           pil_image.BICUBIC))\n",
    "            input_img_data = [process_image(img, input_img_data[0])]\n",
    "\n",
    "        # 解码得到输入激活图像\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        e_time = time.time()\n",
    "        print('Costs of filter {:3}: {:5.0f} ( {:4.2f}s )'.format(filter_index,\n",
    "                                                                  loss_value,\n",
    "                                                                  e_time - s_time))\n",
    "        return img, loss_value\n",
    "\n",
    "    def _draw_filters(filters, n=None):\n",
    "        \"\"\"\n",
    "        绘制得到最佳的卷积核输入图像(激活均值最大),nxn网格形式\n",
    "        \n",
    "        # 输入参数\n",
    "            filters:一系列对应卷积核的生成图片以及损失值(loss)\n",
    "            n:网格维度\n",
    "              n为None的话，则使用最大的网格大小显示\n",
    "        \"\"\"\n",
    "        if n is None:\n",
    "            n = int(np.floor(np.sqrt(len(filters))))\n",
    "\n",
    "        # 认为用于最大损失值的卷积核的激活图是可观的.\n",
    "        # 这里只保留最大的n*n个卷积核\n",
    "        filters.sort(key=lambda x: x[1], reverse=True)\n",
    "        filters = filters[:n * n]\n",
    "\n",
    "        # 先建立一张足够大的黑色背景图\n",
    "        # 如8*8的卷积核数目,图像大小为412*412，间隔为5px \n",
    "        MARGIN = 5\n",
    "        width = n * output_dim[0] + (n - 1) * MARGIN\n",
    "        height = n * output_dim[1] + (n - 1) * MARGIN\n",
    "        stitched_filters = np.zeros((width, height, 3), dtype='uint8')\n",
    "\n",
    "        # 在图像上进行已保存得到的卷积核图像的填充\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                img, _ = filters[i * n + j]\n",
    "                width_margin = (output_dim[0] + MARGIN) * i\n",
    "                height_margin = (output_dim[1] + MARGIN) * j\n",
    "                stitched_filters[\n",
    "                    width_margin: width_margin + output_dim[0],\n",
    "                    height_margin: height_margin + output_dim[1], :] = img\n",
    "\n",
    "        # save the result to disk\n",
    "        # 将得到的图像结果存盘\n",
    "        save_img('out_pics/vgg_{0:}_{1:}x{1:}.png'.format(layer_name, n), stitched_filters)\n",
    "\n",
    "    #　正式进行图片输出    \n",
    "    # 输入图片的占位符(placeholder)\n",
    "    assert len(model.inputs) == 1\n",
    "    input_img = model.inputs[0]\n",
    "\n",
    "    # 得到每个主要层(key layer)的符号输出(每个层的唯一标识名称)\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "\n",
    "    output_layer = layer_dict[layer_name]\n",
    "    assert isinstance(output_layer, layers.Conv2D)\n",
    "\n",
    "    # 得到需要处理的滤波器范围\n",
    "    filter_lower = filter_range[0]\n",
    "    filter_upper = (filter_range[1]\n",
    "                    if filter_range[1] is not None\n",
    "                    else len(output_layer.get_weights()[1]))\n",
    "    assert(filter_lower >= 0\n",
    "           and filter_upper <= len(output_layer.get_weights()[1])\n",
    "           and filter_upper > filter_lower)\n",
    "    print('Compute filters {:} to {:}'.format(filter_lower, filter_upper))\n",
    "\n",
    "    # 迭代通过每个滤波器并得到对应的激活图\n",
    "    processed_filters = []\n",
    "    for f in range(filter_lower, filter_upper):\n",
    "        img_loss = _generate_filter_image(input_img, output_layer.output, f)\n",
    "\n",
    "        if img_loss is not None:\n",
    "            processed_filters.append(img_loss)\n",
    "\n",
    "    print('{} filter processed.'.format(len(processed_filters)))\n",
    "    # 最终绘制并保存最佳的滤波器图像到硬盘\n",
    "    _draw_filters(processed_filters)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # the name of the layer we want to visualize\n",
    "    # (see model definition at keras/applications/vgg16.py)\n",
    "    # 需要定义我们需要可视化的层的名字\n",
    "    # 模型定义可在　keras/applications/vgg16.py中得到\n",
    "    # 也可以通过  \"summary()\"函数得到\n",
    "    LAYER_NAME = 'block5_conv1'\n",
    "\n",
    "    # 通过ImageNet权重进行VGG16网络的构建\n",
    "    vgg = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "    print('Model loaded.')\n",
    "    vgg.summary()\n",
    "\n",
    "    #　调用可视化函数\n",
    "    visualize_layer(vgg, LAYER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
