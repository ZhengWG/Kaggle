{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras下对几个基本案例进行练习。\n",
    "软件环境：\n",
    "python3.5 tensorflow1.12.0 keras.2.2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编写自己的层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编写自己的层需要实现自己的方法：`build(input_shape)`,`call(x)`和`compute_output_shape(input_shape)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        # super函数调用父类方法\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # 为该层创建一个可训练的权重\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(input_shape[0][1], self.output_dim),\n",
    "                                      initializer='unifornm',\n",
    "                                      trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        assert isinstance(x, list)\n",
    "        a, b = x\n",
    "        return [K.dot(a, self.kernel)+b, K.mean(b, axis=-1)]\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        shape_a, shape_b = input_shape\n",
    "        return [(shape_a[0], self.output_dim), shape_b[:,-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图像分类使用示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用ResNet50进行ImageNet分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02504458', 'African_elephant', 0.65953755), ('n01871265', 'tusker', 0.22291991), ('n02504013', 'Indian_elephant', 0.11643972)]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = 'pics/elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "# axis=0中添加数据,扩展数组\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "# 将结果解码为元组列表 (class, description, probability)\n",
    "# (一个列表代表批次中的一个样本）\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用VGG16提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[[[6.00270462e+00 0.00000000e+00 1.69574032e+01 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 5.96835594e+01 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 5.50802612e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    3.95212593e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 1.89220829e+01 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 2.45044804e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 1.86264019e+01\n",
      "    0.00000000e+00 0.00000000e+00 2.16461563e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 1.64715023e+01 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 2.21479855e+01 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 1.52736940e+01 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    3.86444020e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 8.53250980e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 5.95303011e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    2.36279774e+00 4.09699631e+01 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 1.05344458e+01 0.00000000e+00\n",
      "    0.00000000e+00 1.78553562e+01 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 1.86760941e+01\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 2.14552193e+01 0.00000000e+00 6.40742445e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    1.54010105e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 3.24764023e+01\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    4.54562807e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 1.08361454e+01 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 7.94454241e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 6.13945961e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    6.79066002e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    4.00795341e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 2.44787445e+01 6.22394657e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    2.66669798e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 4.56193924e-01 0.00000000e+00 0.00000000e+00\n",
      "    9.43599606e+00 0.00000000e+00 0.00000000e+00 5.42232990e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 1.22626333e+01 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 1.05229902e+01\n",
      "    4.66917648e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "# GPU性能不够，禁用GPU，用CPU来跑\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "print('Model loaded.')\n",
    "model.summary()\n",
    "\n",
    "img_path = 'pics/elephant.jpg'\n",
    "# target_size根据内存情况进行修改,default:224*224\n",
    "img = image.load_img(img_path, target_size=(40, 40))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "features = model.predict(x)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从VGG19的任意中间层中抽取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "=================================================================\n",
      "Total params: 10,585,152\n",
      "Trainable params: 10,585,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[[[   0.           0.           0.        ...    0.\n",
      "    1078.2617       0.       ]\n",
      "   [   0.           0.           0.        ...    0.\n",
      "     412.34436      0.       ]\n",
      "   [   0.           0.           0.        ...    0.\n",
      "     223.36414      0.       ]\n",
      "   ...\n",
      "   [ 323.9225     248.39288      0.        ...    0.\n",
      "       0.           0.       ]\n",
      "   [ 488.28696      0.           0.        ...    0.\n",
      "      97.32691      0.       ]\n",
      "   [ 374.5162       0.         151.77719   ...    0.\n",
      "     355.63834      0.       ]]\n",
      "\n",
      "  [[   0.         236.98703      0.        ...    0.\n",
      "     277.4233       5.586549 ]\n",
      "   [   0.           6.8692183    0.        ...   51.65116\n",
      "       0.           0.       ]\n",
      "   [   0.           0.           0.        ...    0.\n",
      "       0.           0.       ]\n",
      "   ...\n",
      "   [ 201.13338      0.           0.        ...    0.\n",
      "       0.           0.       ]\n",
      "   [ 521.1449       0.           0.        ...    0.\n",
      "       0.           0.       ]\n",
      "   [ 584.84064     71.10789      0.        ...    0.\n",
      "      62.945618     0.       ]]\n",
      "\n",
      "  [[   0.        1277.0269       0.        ...    0.\n",
      "       0.           0.       ]\n",
      "   [ 157.95502   1164.9867       0.        ...    0.\n",
      "       0.         319.05356  ]\n",
      "   [   0.         221.09625      0.        ...    0.\n",
      "     168.74942      0.       ]\n",
      "   ...\n",
      "   [   0.           0.           0.        ...    0.\n",
      "       0.           0.       ]\n",
      "   [   0.         653.115        0.        ...    0.\n",
      "       0.           0.       ]\n",
      "   [  32.10885   1174.8129       0.        ...    0.\n",
      "       0.          98.5298   ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[   0.         197.65906     37.89203   ...    0.\n",
      "       0.           0.       ]\n",
      "   [   0.           0.           0.        ...    0.\n",
      "       0.           0.       ]\n",
      "   [   0.           0.           0.        ...    0.\n",
      "       0.           0.       ]\n",
      "   ...\n",
      "   [ 167.67442      0.         621.42194   ...  320.50616\n",
      "       0.           0.       ]\n",
      "   [  25.070501    73.664635   403.98788   ...    0.\n",
      "       0.           0.       ]\n",
      "   [ 304.7185       0.           0.        ...    0.\n",
      "       0.           0.       ]]\n",
      "\n",
      "  [[   0.         477.0775       0.        ...    0.\n",
      "       0.           0.       ]\n",
      "   [   0.         698.8495       0.        ...   14.95361\n",
      "       0.           0.       ]\n",
      "   [   0.         197.49695      0.        ...    0.\n",
      "       0.           0.       ]\n",
      "   ...\n",
      "   [ 564.99963      0.         134.48747   ...    0.\n",
      "       0.           0.       ]\n",
      "   [   0.        1327.4567       0.        ...    0.\n",
      "     188.29167      0.       ]\n",
      "   [ 168.85065    844.21344      0.        ...    0.\n",
      "     290.83456      0.       ]]\n",
      "\n",
      "  [[   0.           0.           0.        ...    0.\n",
      "      93.44571    271.4439   ]\n",
      "   [   0.           0.           0.        ...    0.\n",
      "       0.           0.       ]\n",
      "   [   0.           0.           0.        ...    0.\n",
      "       0.           0.       ]\n",
      "   ...\n",
      "   [ 495.35916      0.           0.        ...    0.\n",
      "       0.           0.       ]\n",
      "   [   0.           0.          44.81439   ...    0.\n",
      "       0.           0.       ]\n",
      "   [   0.           0.         416.51477   ...    0.\n",
      "       0.         346.07434  ]]]]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# GPU性能不够，禁用GPU，用CPU来跑\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "base_model = VGG19(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n",
    "\n",
    "img_path = 'pics/elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "print('Model loaded.')\n",
    "model.summary()\n",
    "\n",
    "block4_pool_features = model.predict(x)\n",
    "\n",
    "print(block4_pool_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在新类上微调InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv2d_1\n",
      "2 batch_normalization_1\n",
      "3 activation_1\n",
      "4 conv2d_2\n",
      "5 batch_normalization_2\n",
      "6 activation_2\n",
      "7 conv2d_3\n",
      "8 batch_normalization_3\n",
      "9 activation_3\n",
      "10 max_pooling2d_1\n",
      "11 conv2d_4\n",
      "12 batch_normalization_4\n",
      "13 activation_4\n",
      "14 conv2d_5\n",
      "15 batch_normalization_5\n",
      "16 activation_5\n",
      "17 max_pooling2d_2\n",
      "18 conv2d_9\n",
      "19 batch_normalization_9\n",
      "20 activation_9\n",
      "21 conv2d_7\n",
      "22 conv2d_10\n",
      "23 batch_normalization_7\n",
      "24 batch_normalization_10\n",
      "25 activation_7\n",
      "26 activation_10\n",
      "27 average_pooling2d_1\n",
      "28 conv2d_6\n",
      "29 conv2d_8\n",
      "30 conv2d_11\n",
      "31 conv2d_12\n",
      "32 batch_normalization_6\n",
      "33 batch_normalization_8\n",
      "34 batch_normalization_11\n",
      "35 batch_normalization_12\n",
      "36 activation_6\n",
      "37 activation_8\n",
      "38 activation_11\n",
      "39 activation_12\n",
      "40 mixed0\n",
      "41 conv2d_16\n",
      "42 batch_normalization_16\n",
      "43 activation_16\n",
      "44 conv2d_14\n",
      "45 conv2d_17\n",
      "46 batch_normalization_14\n",
      "47 batch_normalization_17\n",
      "48 activation_14\n",
      "49 activation_17\n",
      "50 average_pooling2d_2\n",
      "51 conv2d_13\n",
      "52 conv2d_15\n",
      "53 conv2d_18\n",
      "54 conv2d_19\n",
      "55 batch_normalization_13\n",
      "56 batch_normalization_15\n",
      "57 batch_normalization_18\n",
      "58 batch_normalization_19\n",
      "59 activation_13\n",
      "60 activation_15\n",
      "61 activation_18\n",
      "62 activation_19\n",
      "63 mixed1\n",
      "64 conv2d_23\n",
      "65 batch_normalization_23\n",
      "66 activation_23\n",
      "67 conv2d_21\n",
      "68 conv2d_24\n",
      "69 batch_normalization_21\n",
      "70 batch_normalization_24\n",
      "71 activation_21\n",
      "72 activation_24\n",
      "73 average_pooling2d_3\n",
      "74 conv2d_20\n",
      "75 conv2d_22\n",
      "76 conv2d_25\n",
      "77 conv2d_26\n",
      "78 batch_normalization_20\n",
      "79 batch_normalization_22\n",
      "80 batch_normalization_25\n",
      "81 batch_normalization_26\n",
      "82 activation_20\n",
      "83 activation_22\n",
      "84 activation_25\n",
      "85 activation_26\n",
      "86 mixed2\n",
      "87 conv2d_28\n",
      "88 batch_normalization_28\n",
      "89 activation_28\n",
      "90 conv2d_29\n",
      "91 batch_normalization_29\n",
      "92 activation_29\n",
      "93 conv2d_27\n",
      "94 conv2d_30\n",
      "95 batch_normalization_27\n",
      "96 batch_normalization_30\n",
      "97 activation_27\n",
      "98 activation_30\n",
      "99 max_pooling2d_3\n",
      "100 mixed3\n",
      "101 conv2d_35\n",
      "102 batch_normalization_35\n",
      "103 activation_35\n",
      "104 conv2d_36\n",
      "105 batch_normalization_36\n",
      "106 activation_36\n",
      "107 conv2d_32\n",
      "108 conv2d_37\n",
      "109 batch_normalization_32\n",
      "110 batch_normalization_37\n",
      "111 activation_32\n",
      "112 activation_37\n",
      "113 conv2d_33\n",
      "114 conv2d_38\n",
      "115 batch_normalization_33\n",
      "116 batch_normalization_38\n",
      "117 activation_33\n",
      "118 activation_38\n",
      "119 average_pooling2d_4\n",
      "120 conv2d_31\n",
      "121 conv2d_34\n",
      "122 conv2d_39\n",
      "123 conv2d_40\n",
      "124 batch_normalization_31\n",
      "125 batch_normalization_34\n",
      "126 batch_normalization_39\n",
      "127 batch_normalization_40\n",
      "128 activation_31\n",
      "129 activation_34\n",
      "130 activation_39\n",
      "131 activation_40\n",
      "132 mixed4\n",
      "133 conv2d_45\n",
      "134 batch_normalization_45\n",
      "135 activation_45\n",
      "136 conv2d_46\n",
      "137 batch_normalization_46\n",
      "138 activation_46\n",
      "139 conv2d_42\n",
      "140 conv2d_47\n",
      "141 batch_normalization_42\n",
      "142 batch_normalization_47\n",
      "143 activation_42\n",
      "144 activation_47\n",
      "145 conv2d_43\n",
      "146 conv2d_48\n",
      "147 batch_normalization_43\n",
      "148 batch_normalization_48\n",
      "149 activation_43\n",
      "150 activation_48\n",
      "151 average_pooling2d_5\n",
      "152 conv2d_41\n",
      "153 conv2d_44\n",
      "154 conv2d_49\n",
      "155 conv2d_50\n",
      "156 batch_normalization_41\n",
      "157 batch_normalization_44\n",
      "158 batch_normalization_49\n",
      "159 batch_normalization_50\n",
      "160 activation_41\n",
      "161 activation_44\n",
      "162 activation_49\n",
      "163 activation_50\n",
      "164 mixed5\n",
      "165 conv2d_55\n",
      "166 batch_normalization_55\n",
      "167 activation_55\n",
      "168 conv2d_56\n",
      "169 batch_normalization_56\n",
      "170 activation_56\n",
      "171 conv2d_52\n",
      "172 conv2d_57\n",
      "173 batch_normalization_52\n",
      "174 batch_normalization_57\n",
      "175 activation_52\n",
      "176 activation_57\n",
      "177 conv2d_53\n",
      "178 conv2d_58\n",
      "179 batch_normalization_53\n",
      "180 batch_normalization_58\n",
      "181 activation_53\n",
      "182 activation_58\n",
      "183 average_pooling2d_6\n",
      "184 conv2d_51\n",
      "185 conv2d_54\n",
      "186 conv2d_59\n",
      "187 conv2d_60\n",
      "188 batch_normalization_51\n",
      "189 batch_normalization_54\n",
      "190 batch_normalization_59\n",
      "191 batch_normalization_60\n",
      "192 activation_51\n",
      "193 activation_54\n",
      "194 activation_59\n",
      "195 activation_60\n",
      "196 mixed6\n",
      "197 conv2d_65\n",
      "198 batch_normalization_65\n",
      "199 activation_65\n",
      "200 conv2d_66\n",
      "201 batch_normalization_66\n",
      "202 activation_66\n",
      "203 conv2d_62\n",
      "204 conv2d_67\n",
      "205 batch_normalization_62\n",
      "206 batch_normalization_67\n",
      "207 activation_62\n",
      "208 activation_67\n",
      "209 conv2d_63\n",
      "210 conv2d_68\n",
      "211 batch_normalization_63\n",
      "212 batch_normalization_68\n",
      "213 activation_63\n",
      "214 activation_68\n",
      "215 average_pooling2d_7\n",
      "216 conv2d_61\n",
      "217 conv2d_64\n",
      "218 conv2d_69\n",
      "219 conv2d_70\n",
      "220 batch_normalization_61\n",
      "221 batch_normalization_64\n",
      "222 batch_normalization_69\n",
      "223 batch_normalization_70\n",
      "224 activation_61\n",
      "225 activation_64\n",
      "226 activation_69\n",
      "227 activation_70\n",
      "228 mixed7\n",
      "229 conv2d_73\n",
      "230 batch_normalization_73\n",
      "231 activation_73\n",
      "232 conv2d_74\n",
      "233 batch_normalization_74\n",
      "234 activation_74\n",
      "235 conv2d_71\n",
      "236 conv2d_75\n",
      "237 batch_normalization_71\n",
      "238 batch_normalization_75\n",
      "239 activation_71\n",
      "240 activation_75\n",
      "241 conv2d_72\n",
      "242 conv2d_76\n",
      "243 batch_normalization_72\n",
      "244 batch_normalization_76\n",
      "245 activation_72\n",
      "246 activation_76\n",
      "247 max_pooling2d_4\n",
      "248 mixed8\n",
      "249 conv2d_81\n",
      "250 batch_normalization_81\n",
      "251 activation_81\n",
      "252 conv2d_78\n",
      "253 conv2d_82\n",
      "254 batch_normalization_78\n",
      "255 batch_normalization_82\n",
      "256 activation_78\n",
      "257 activation_82\n",
      "258 conv2d_79\n",
      "259 conv2d_80\n",
      "260 conv2d_83\n",
      "261 conv2d_84\n",
      "262 average_pooling2d_8\n",
      "263 conv2d_77\n",
      "264 batch_normalization_79\n",
      "265 batch_normalization_80\n",
      "266 batch_normalization_83\n",
      "267 batch_normalization_84\n",
      "268 conv2d_85\n",
      "269 batch_normalization_77\n",
      "270 activation_79\n",
      "271 activation_80\n",
      "272 activation_83\n",
      "273 activation_84\n",
      "274 batch_normalization_85\n",
      "275 activation_77\n",
      "276 mixed9_0\n",
      "277 concatenate_1\n",
      "278 activation_85\n",
      "279 mixed9\n",
      "280 conv2d_90\n",
      "281 batch_normalization_90\n",
      "282 activation_90\n",
      "283 conv2d_87\n",
      "284 conv2d_91\n",
      "285 batch_normalization_87\n",
      "286 batch_normalization_91\n",
      "287 activation_87\n",
      "288 activation_91\n",
      "289 conv2d_88\n",
      "290 conv2d_89\n",
      "291 conv2d_92\n",
      "292 conv2d_93\n",
      "293 average_pooling2d_9\n",
      "294 conv2d_86\n",
      "295 batch_normalization_88\n",
      "296 batch_normalization_89\n",
      "297 batch_normalization_92\n",
      "298 batch_normalization_93\n",
      "299 conv2d_94\n",
      "300 batch_normalization_86\n",
      "301 activation_88\n",
      "302 activation_89\n",
      "303 activation_92\n",
      "304 activation_93\n",
      "305 batch_normalization_94\n",
      "306 activation_86\n",
      "307 mixed9_1\n",
      "308 concatenate_2\n",
      "309 activation_94\n",
      "310 mixed10\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# 构建不带分类器的预训练模型:include_top=False\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# 添加全局平均池化层\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# 添加一个全连接层\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# 添加一个分类器，假设我们有200个类\n",
    "predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "# 构建我们需要训练的完整模型\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 首先，我们只训练顶部的几层（随机初始化的层）\n",
    "# 锁住所有 InceptionV3 的卷积层\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# 编译模型（一定要在锁层以后操作）\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# 在新的数据集上训练几代\n",
    "# 参数:self,generator,steps_per_epoch,epochs,verbose,validation_data,\n",
    "# validation_steps,class_weight,sample_weight,workers,max_q_size,pickle_safe,initial_epoch\n",
    "# 重要的参数有:generator，为生成器函数，生成输入，target(标签)等数据输入;\n",
    "# steps_per_epoch:输入数据的batch数目，自动得到batches数目?\n",
    "# epochs:数据迭代数目\n",
    "# 可利用yield函数进行生成数据:如：\n",
    "# def generate_arrays_from_file(path):\n",
    "#    while 1:\n",
    "#    f = open(path)\n",
    "#    for line in f:\n",
    "#        x1, x2, y = process_line(line)\n",
    "#        yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
    "#    f.close()\n",
    "# model.fit_generator(generate_arrays_from_file('/my_file.txt'), steps_per_epoch=10000, epochs=10)\n",
    "\n",
    "model.fit_generator(...)\n",
    "\n",
    "# 现在顶层应该训练好了，让我们开始微调 Inception V3 的卷积层。\n",
    "# 我们会锁住底下的几层，然后训练其余的顶层。\n",
    "\n",
    "# 让我们看看每一层的名字和层号，查看应该锁多少层：\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# 我们选择训练最上面的两个 Inception block\n",
    "# 也就是说锁住前面249层，然后放开之后的层。\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# 我们需要重新编译模型，才能使上面的修改生效\n",
    "# 让我们设置一个很低的学习率，使用 SGD 来微调\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
    "\n",
    "# 我们继续训练模型，这次我们训练最后两个 Inception block\n",
    "# 和两个全连接层\n",
    "model.fit_generator(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过自定义输入张量构建InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input\n",
    "\n",
    "# 这也可能是不同的 Keras 模型或层的输出\n",
    "input_tensor = Input(shape=(224, 224, 3))  # 假定 K.image_data_format() == 'channels_last'\n",
    "\n",
    "model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
